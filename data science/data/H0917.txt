ID=H0917
URL=http://bostonreview.mit.edu/br23.1/gintis.html
SIZE=33422
DATE=11/07/2002
TIME=17:09:12
DATASET=Biology
HTML=<!doctype HTML public "-//W30//DTD W3 HTML 2.0//EN"><HEAD><TITLE>Boston Review | Herbert Gintis and H. Allen Orr: Why Do We Cooperate?</TITLE><META name="description" content="Darwin, Darwinism, reciprocity, altruism,sociobiology, matt ridley, homo economicus"><META name="keywords" content=""></HEAD><BODY bgcolor="ffffff"><DIV ALIGN=CENTER><table width=585 cellpadding="0" cellspacing="0" border="0" BGCOLOR="#CCCCCC"><tr valign="top"><td colspan="3"><table border="0" width="585" cellspacing="0" cellpadding="0"><tr valign="TOP"><TD ALIGN=CENTER VALIGN=TOP WIDTH="120"><A HREF="http://bostonreview.mit.edu" target=_top><IMG SRC="http://bostonreview.mit.edu/images/br1.gif" ALT="Boston Review" ALIGN=MIDDLE WIDTH="118" HEIGHT="60" BORDER="0"></A></td><td width="8" align=right></td><td width="455" VALIGN=TOP align=left>		<A HREF="http://bostonreview.mit.edu/.click?http://www.hup.harvard.edu/Featured/jefferson/index.html" TARGET="_blank">	<IMG SRC="http://bostonreview.mit.edu/images/ads/wallacebanner.gif" alt="Advertisement: Harvard University Press" ALIGN=TOP WIDTH="455" HEIGHT="60" BORDER="0"></A></td></tr></table></td></tr></table></DIV><hr width="585" align="CENTER"><BR><blockquote><CENTER><H1><B>Why Do We Cooperate?</B></H1><H3><B><I>An exchange on genes and culture.</I></B></H3></CENTER><HR WIDTH=25%><H1><B><I>Cultural Darwinism</B></I></H1><B>Herbert Gintis</B><BR><P>While I am more sympathetic to Matt Ridley's <I>The Origins of Virtue:  Human Instincts and the Evolution of Cooperation</I> than Allen Orr is (<A HREF="../BR22.5/orr.html">"The Softer Side of Sociobiology,"</A> <I>BR</I> October/November 1997), I find three of Orr's criticisms right on the mark. First, a genetic theory is not needed to explain human cooperation. Indeed, basic economic theory can explain why people sustain cooperative relationships in the long-term, repeated interactions stressed in Ridley's book. Even using the narrowest of concepts of self-interest and instrumental rationality (the <I>Homo economicus</I> of textbook economics), we can explain much of the cooperation we see around us as "enlightened self-interest." There is no harm in following the animal behaviorists, who call this "reciprocal altruism," but we should keep in mind that there is really no element of altruism (i.e., sacrificing one's own interests in favor of another's) involved.</P><P>Second, Ridley's stress on the genetic basis of human cooperation is not mandated by the facts uncovered by what we may call "socio-evolutionary theory"--the evolutionary study of behavior across the biological spectrum. There is indeed a <I>prima facie</I> case for a genetic basis for human sociality: Cooperation occurs in a wide variety of life-forms (ants, termites, bees, mole rats, lions, etc.); most of these have only the most rudimentary forms of culture (information and behavior patterns transmitted phenotypically across generations), if any; cooperation in most species is thus genetically transmitted; so probably the same is true of <I>Homo sapiens</I>. </P><P>The mechanisms developed to explain sociality among nonhumans, however, do not explain sociality in humans. The key fact about human society is that cooperation regularly takes place among <I>non-kin</I>, whereas except perhaps in some nonhuman primates, cooperation in the animal world is solidly kin-based: individuals aid others with whom they share genes by common descent (the so-called "inclusive fitness" analyzed by William Hamilton and others).<A HREF ="#1">1</a></P><P>Indeed, the lack of continuity between us and the nonhuman social animals makes a non-genetic explanation of human cooperation plausible. Of course we do share with the rest of nature an inborn tendency to be altruistic towards kin. But our widespread engagement in extrafamilial cooperation and caring has virtually no counterpart elsewhere in nature, and it is this aspect of human sociality that accounts for civilization as we know it. Orr rightly stresses this point--though primatologists like Frans de Waal would qualify this statement, and many game theorists believe that the study of animal behavior helps us understand human behavior, though it does not explain the uniquely human forms of prosociality.<A HREF ="#2">2</a></P><P>Third, Ridley's anti-statist conservatism does not follow from his position on the Darwinian roots of cooperation. Moreover, by injecting his political conservatism into the description of current research in socio-evolutionary theory, Ridley reinforces the stereotype of this  research as a reactionary, right-wing intellectual movement. Nothing could be further from the truth. In my experience with many researchers in this area, I find that they generally range from mildly to strongly progressive. Moreover, while the implications of behavioral research may ultimately be of overarching importance for social theory, they are much more likely to challenge all the currently popular preconceptions rather than to fit snugly into some intellectual tradition inherited from the past. Indicative of this iconoclastic position is the dual stress in socio-evolutionary theory on the dynamic interaction of cooperation and competition, conflict and cooperation, as well as self-interest and altruism, in explaining the emergence of contemporary forms of human behavior.</P><P>However, I think Ridley gets two additional and supremely important points wrong, and Orr does not object. First, socio-evolutionary research has applied Darwinian concepts to <I>both</I> culture <I>and</I> genes. The idea that human culture evolves through the Darwinian processes of adaptation, selection, and mutation is expressed in some of the most important contributions to the field, including Robert Boyd and Peter Richerson's justly famous <I>Culture and the Evolutionary Process</I> and Luigi Feldman and Marcus Cavalli-Sforza's equally influential <I>Cultural Transmission and Evolution.</I><A HREF ="#3">3</a> Indeed, most researchers in the field speak of "gene-culture coevolution," and are agnostic as to the relative importance of the two in explaining human behavior.</P><P>Moreover, gene-culture coevolutionary theory is deeply destructive to traditional conceptions of culture, politics, and social policy, whatever the "balance" between the genetic and non-genetic elements. The reason for this is that such a theory views culture as having a life of its own, rather than being a static reflection of such social institutions as church, schooling, and state propaganda. In such a view, culture evolves through mutation and selection on both the genetic and phenotypic level, and the organized forces of society are but one element in nexus of forces affecting cultural change. This may be why the Soviet Union was never able to create "socialist Man," and movements for gender and racial equality emerged in the United States despite the heavy weight of racist and sexist traditionalism. To some on both right and left, the idea that culture has a dynamic that can be influenced, but not countermanded, may be deeply disturbing, but to others (including myself) it holds out the possibility of influencing our future as a species more powerfully than ever before.</P><P>Second, human beings exhibit a form of <I>strong reciprocity </I>that cannot be explained by reciprocal altruism or enlightened self-interest. Reciprocal altruism cannot explain why people vote, give to charity, participate in large collective actions to transform social institutions, or sacrifice themselves in battle. In each of these cases, people incur costs while contributing to a collective good, but cannot expect a compensating, long-term benefit to result from their contribution. A socio-evolutionary theory must explain such behaviors, which lie at the very heart of any explanation of the shape of human civilization. <I>Homo economicus</I> cooperates only when it serves his purposes. When his interests are not served by cooperating--for instance when dealing with people who cannot help him, or when he can commit acts of violence without fear of apprehension--<I>Homo economicus</I> is what we would commonly call a sociopath: an individual totally indifferent to the well-being of others.</P><P>The fact is that most of us are <I>not</I> sociopaths. A suggestive body of experimental evidence points to a new <I>persona, </I>whom we may call <I>Homo reciprocans. Homo reciprocans</I> comes to new social situations with a propensity to cooperate, responds to prosocial behavior on the part of others by maintaining or increasing his level of cooperation, and responds to selfish, free-riding behavior on the part of others by retaliating against the offenders, even at a cost to himself, and even when he could not reasonably expect future personal gains from such retaliation. <I>Homo reciprocans</I> is neither the unconditional altruist adored by the left, nor the rationally self-interested <I>Homo economicus</I> championed by the right. Rather, he is a conditional cooperator--someone who cooperates when he expects others to behave in a socially responsible manner--and a vindictive retaliator--someone who punishes free-riders. </P><P>Among the most important of the laboratory experiments used to reveal the character of <I>Homo reciprocans</I> is the "public-goods game," designed to illuminate such problems as the voluntary payment of taxes and the restriction of one's use of an endangered environmental resource. The following is a common variant. Ten subjects are told that $1 will be deposited in each of their "private accounts" as a reward for participating in each round of the experiment. For every $1 a subject moves from his or her "private account" to the "public account," the experimenter will deposit 50 cents in the private accounts of each of the subjects at the end of the game. This process will be repeated ten times, and at the end, the subjects can take home whatever they have in their private accounts.</P><P>If all ten subjects are perfectly cooperative, each puts $1 in the public account at the end of a round, generating a public pool of $10; the experimenter then puts $5 in the private account of each subject. After ten rounds of this, each subject has $50. Suppose, by contrast, that one subject is perfectly selfish, while the others are cooperative. The selfish one keeps all his dollars in his private account, whereas the cooperative ones continue to put $1 in the public pool each round. In this case, the selfish subject who takes a free ride on the cooperative contributions of others ends up with $55 at the end of the game, while the other players end up with $45 each. But if all players try to get this selfish payoff, then no one contributes to the public pool, and each ends up with $10 at the end of the game. And if one player cooperates, while the others are all selfish, that player will end up with $5 at the end of the game, while the others will get $15. It is thus clear that this is indeed an "iterated prisoner's dilemma"--whatever other players do on a particular round, a player's highest payoff comes from contributing nothing to the public account. If others cooperate, it is best to take a free ride; if others are selfish, it is best to join them. But if no one contributes, all receive less than they would had all cooperated.</P><P>Public-goods experiments of this type have been run literally hundreds of times, under varying conditions, since the pioneering work of the sociologist Gerald Marwell, the psychologist Robyn Dawes, the political scientist John Orbell, and the economists R. Mark Isaac and James Walker in the late 1970s and early 1980s. This research has shown that only a fraction of subjects conform to the <I>Homo economicus</I> model, contributing nothing to the public account. Rather, in the early stages of the game, people generally make contributions that average about half-way between the perfectly cooperative and the perfectly selfish levels. In the later stages of the game, contributions decay until at the end, they are close to the <I>Homo economicus</I> level.</P><P>Proponents of the <I>Homo economicus</I> model initially suggested that the reason for decay of public contribution is that participants do not understand the game at first, and as they begin to learn it, they realize the superiority of the free-riding strategy. But more recent experiments undercut this interpretation. For instance, James Andreoni has found that when the whole process is repeated with the same subjects, the initial levels of cooperation are restored at the start of a new round, but that cooperation once again decays as the game progresses.<A HREF = "#4">4</a> Andreoni suggests a <I>Homo reciprocans</I> explanation for the decay of cooperation: public-spirited contributors want to retaliate against free-riders and the only way available to them in the game is by not contributing themselves.<A HREF = "#5">5</a></P><P>Support for this <I>Homo reciprocans</I> interpretation has been supplied by the work of Ernst Fehr and Simon GŠchter,<A HREF = "#6">6</a> who allowed cooperators to retaliate directly against free-riders, but at a cost to themselves. In this context, the textbook <I>Homo economicus</I> would always free-ride, and never punish other free-riders, because punishing is itself a public good of little personal benefit to the punisher. But Fehr and GŠchter found that in fact people do retaliate, and that potential free-riders, expecting this to happen, do not free-ride. The result is that cooperation begins, as expected, with about half the participants and over successive rounds <I>rises </I>until virtually all of them are cooperating.</P><P>Strong reciprocity suggests an underlying commitment to fairness. This commitment is brought out in a series of experiments involving what have come to be known as "ultimatum games" and "dictator games." In the ultimatum game,<A HREF = "#7">7</a> the experimenter chooses two subjects and tells the first: "I am going to provisionally allocate $10 to you. You, the proposer, can offer any amount of this, from one cent to the whole $10, to the other player, the respondent. If the respondent accepts your offer, he gets that amount and you get whatever is left over. If the respondent rejects your offer, I take back the $10 and you each get nothing." In this game, if both proposer and respondent were examples of <I>Homo economicus</I>, the proposer would offer the respondent one cent, the respondent would accept (one cent is better than nothing), and the proposer would walk away with $9.99. In fact, as many replications of this experiment have documented, under varying conditions and with varying amounts of money, proposers commonly offer the respondent very substantial amounts, and respondents frequently reject offers that are below one-third of the total.<A HREF ="#8">8</a> Similar results have occurred in experiments with stakes as high as three months' earnings.</P><P>When asked why they offer more than one cent, proposers commonly say that they are afraid that respondents will consider low offers unfair and reject them to punish the proposer's unfairness. When respondents reject offers, they give virtually the same reasons for their actions. To be sure, the proposers' actions might be explained by selfish motives: if the proposer makes a low-ball offer that the respondent rejects, then the proposer gets nothing. But selfishness cannot explain the respondents' behavior: the respondent who rejects a low offer is simply turning down money. Instead, it appears that respondents reject offers considered to be unfair, and that proposers, anticipating such rejection, make substantial offers. Of course, proposers will be successful only if they can anticipate what respondents will consider fair. </P><P>Further experimental evidence suggests that they can. A study conducted in four different countries (the United States, Yugoslavia, Japan, and Israel) found that while the level of offers differed in different countries, the probability of an offer being rejected did not.<A HREF = "#9">9</a> This indicates that both proposers and responders share the same notion of what is considered "fair" in that society. Evidence from dictator games--in which the proposer offers a split of the money and the respondent has no choice but to accept--indicates that proposers, too, may be acting from fairness motives. While proposers could keep all the money themselves, they typically offer respondents a considerable share of the total.<A HREF ="#10">10</a> </P><P>A remarkable aspect of these experiments is the degree to which behaviors are affected by the experimentally contrived social relationship among players. Communication among participants prior to the game, or experimental conditions that reduce the subjective "social distance" among participants, lead to higher and more sustained levels of generosity and cooperation.<A HREF ="#11">11</a> For example, UCLA college students facing a prisoner's dilemma payoff structure tended to cooperate rather than defect when they were anonymously matched with fraternity brothers, but to defect when they were informed that their partner was an LAPD police officer.<A HREF ="#12">12</a> Proposers in another study gave more when told that the respondent was the Red Cross, rather than an experimental subject.<A HREF ="#13">13</a> Finally, when the right to be proposer in the ultimatum game is "earned," by being a "winner" in a general knowledge quiz, proposers offered less, and respondents accepted lower offers.<A HREF ="#14">14</a> It appears that minor manipulations of the social context of interactions may support significant behavioral differences.</P><P>In all the experiments a significant fraction of subjects (about a quarter, typically) conform to the self-interested preferences of <I>Homo economicus</I>, and it is often the self-serving behavior of this minority that, when it goes unpunished, unravels initial generosity and cooperation.</P><P>Is strong reciprocity a culturally or a genetically induced phenomenon? The answer is doubtless that we are genetically disposed to exhibit strong reciprocity, but its intensity and particular manifest forms depend on local cultural conditions and individual experience. It is unlikely that strong reciprocity is purely cultural, since the "eye for an eye" side of reciprocal fairness is frowned upon by the dominant cultural institutions of civilized societies, as well as the dominant religions. Despite this overwhelming cultural bias against retributive justice, individuals who consistently behave according to the "turn the other cheek" precept are very rare, and are widely considered to be fools or saints. It is possible, of course, that strong reciprocity is a predominantly cultural phenomenon, but one that persists through some evolutionary dynamic, despite the hostility of our dominant cultural and religious institutions.</P><P>In sum, I share Matt Ridley's excitement concerning socio-evolutionary theory. I consider it the most promising development in social theory in many years, and one that may very well lead to a long-overdue unification of the behavioral sciences, and a fundamental paradigm shift in the way we conceive of ourselves and our social lives. </P><P><CENTER><B>For more papers by Herbert Gintis, click <A HREF="http://www-unix.oit.umass.edu/~gintis/" TARGET="_blank">here</A>.</B></CENTER></P><hr width=50%><BR><BR><H1><B><I>Allen Orr Replies</B></I></H1><P>Although I think he goes too far in places, Herb Gintis's response seems a step in the right direction. Over the last few years, there has been far too little discussion between social scientists and biologists about cooperation. Indeed, the latest survey of cooperation by a biologist bizarrely begins by announcing that it will ignore all of the "hundreds, if not thousands of experiments on cooperation in humans."<A HREF = "#1a">1</a> This situation is unfortunate. Given that many biologists are animated by dreams of a Biological Theory of human society (one of the few points that Ridley's book managed to establish), how can those thousands of experiments on humans <I>not</I> be relevant? </P><P>The typical sociobiologist seems to reason as follows: It is patently obvious that human culture is based on reciprocity.<A HREF = "#2a">2</a> Money, after all, serves to keep track of such obligations. Thus human cooperation is readily explained by reciprocal altruism, and the sole remaining question is whether animal cooperation <I>also</I> evolved by reciprocal altruism. The sociobiologist's cocksure assumption that he knows what makes humans tick lets him forget, in other words, about two other possibilities: that animals do reciprocal altruism, but <I>people</I> don't; and that neither animals nor people do reciprocal altruism.</P><P>The human cooperation experiments described by Gintis suggest that these possibilities must be taken seriously. Three results are relevant. First, people cooperate early on in public goods games despite the fact that the game's design precludes tit-for-tat-like score-keeping of who's naughty and who's nice. Second, players "irrationally" retaliate against unfair behavior in ultimatum games even when retaliation exacts a price. Third, individuals offer respondents a good share of money in dictator games despite the fact that they are free to keep all the cash.</P><P>I agree with Gintis that these results are not easily explained by a strictly genetic theory like reciprocal altruism. (And they are <I>certainly</I> not explained by traditional economic theory.) </P><P>But, that said, I find myself in the somewhat surprising position of thinking that Gintis goes too far when he claims that the "mechanisms developed to explain sociality among nonhumans . . . do not explain sociality in humans" or that evidence of "strong reciprocity" among non-relatives "cannot be explained by reciprocal altruism." Take the public-goods game. Willingness to cooperate early on could reflect an evolved tendency, a genetic predisposition to cooperate with others until they defect. (And remember, Trivers's genetical theory of reciprocal altruism was specifically intended to explain cooperation among unrelated individuals.) The fact that tit-for-tat-style cooperation doesn't make good sense in a public-goods game--because one can't cooperate with particular players, discriminating between those who cooperate back and those who don't-- may well be beside the point. No one is claiming that our predisposition to cooperate evolved in situations that looked like public-goods games. One need only claim that our tendency to begin by cooperating in such games is an unintended <I>side-effect </I>of an evolved tit-for-tat "start nice" strategy. (By analogy, the fact that insects are drawn to bug zappers is not terribly adaptive. But it would surely be misleading to claim that Darwinism cannot explain this behavior. It is, after all, a fairly obvious unintended side-effect of clearly evolved instincts.) Similar side-effect arguments are possible for the other findings Gintis emphasizes. In dictator games, for instance, proposers may be predisposed to give up resources to respondents since, in our evolutionary history, proposers one day were all too often respondents the next. <I>Ergo</I>, our genes say it pays to be nice, no matter how irrational such behavior is in particular (and artificial) games. Indeed one could go further and argue that--in complex games in which the best strategy is, at first, far from obvious--we are all the more likely to fall back upon (perhaps inappropriate) biological predispositions.<A HREF = "#3a">3</a> </P><P>My claim is certainly not that I find this sort of special pleading satisfying, only that it is possible. Indeed this point highlights a subtle difference between Gintis's position and mine. Though Gintis has no problem with some role for biology, he seems to believe that no strictly genetic explanation of human cooperation between unrelated humans is possible. Moreover, he seems to think that I side with him here. But the point of my review was not that biology <I>cannot</I> be extended to humans, but that this extension has not, so far, been terribly successful. As I emphasized, I have no problem with the <I>possibility</I> that biology explains human cooperation. My problem is with Ridley's attempt to pass off this mere hypothesis as a secure finding, the revolutionary result of a rigorous science. So while Ridley errs in forgetting that reciprocal altruism is a mere hypothesis (and one in trouble at that), Gintis seems to err in believing that it doesn't even count as a hypothesis.</P><P>But I don't want to make too much of this difference, as I find that I agree with the spirit of Gintis's response. Ridley's book <I>does</I> paint a misleadingly genetical portrait of human research, and the "strong reciprocity" result emerging from this work <I>could </I>well pose problems for sociobiology. Indeed it seems to me palpably obvious that humans, unlike birds and bees, bring all variety of "irrational" cultural beliefs to bear on decisions about cooperation--a fact, perhaps, that could count as news only to economists and evolutionary biologists. </P><P><CENTER><B>For more papers by Allen Orr, click <A HREF="http://www.rochester.edu/College/BIO/faculty/Orr.html" TARGET="_blank">here</A>.</B></CENTER></P><hr width=50%><P><A NAME=1>1</A>&nbsp; Virtually all <I>bona fide</I> examples of reciprocal altruism in nonhumans occurs in species closely realted to us, most notably in chimpanzees, who could also be using instrumental rationality in cooperating with others, rather than simply playing out a genetic code. See Frans de Waal, <I>Good Natured: The Origin of Right and Wrong in Humans and Other Animals </I>(Cambridge, Mass.: Harvard University Press, 1997).</P><P><A NAME=2>2</A>&nbsp; This point is elaborated in Samuel Bowles and Herbert Gintis, "The Moral Economy of Community: Structured  Populations and the Evolution of Prosocial Norms," <I>Evolution & and Human Behaviour </I> (1998).</P><P><A NAME=3>3</A>&nbsp; Robert Boyd and Peter J. Richerson, <I>Culture and the Evolutionary Process</I> (Chicago: University of Chicago Press, 1985); Luigi L. Cavalli-Sforza and Marcus W. Feldman, <I>Cultural Transmission and Evolution</I> (Princeton: Princeton University Press, 1981).</P><P><A NAME=4>4</A>&nbsp; James Andreoni, "Why Free Ride? Strategies and Learning in Public Good Experiments," <I>Journal of Public Economics </I>37 (1988): 291-304.</P><P><A NAME=5>5</A>&nbsp; James Andreoni, "Cooperation in Public Goods Experiments: Kindness or Confusion," <I>American Economic Review</I> 85, 4 (1995): 891-904.</P><P><A NAME=6>6</A>&nbsp; Ernst Fehr and Simon G&auml;chter, "Cooperation and Punishment," 1996. Working Paper, Institute for Empirical Economic Research, University of Zilrich.</P><P><A NAME=7>7</A>&nbsp; Werner G&uuml;th et al., "An Experimental Analysis of Ultimatum Bargaining," <I>Journal of Economic Behaviour and Organization</I> 3 (May 1982): 367-388.</P><P><A NAME=8>8</A>&nbsp; For examples and analyses of ultimatum games, see Robert Forsythe et al., "Replicability, Fairness and Pay in Experiments with Simple Bargaining Games," <I>Games and Economic Behaviour</I> 6, 3 (May 1994): 347-69; Elizabeth Hoffman et al., "Preferences, Property Rights, and Anonymity in Bargaining Games," <I>Games and Economic Behaviour</I> 7 (1994): 346-80.</P><P><A NAME=9>9</A>&nbsp; Alvin E. Roth et al., "Bargaining and Market Behaviour in Jerusalem, Ljubljana, Pittsburgh, and Tokyo: An Experimental Study," <I>American Economic Review</I> 81, 5 (December 1991): 1068-95.</P><P><A NAME=10>10</A>&nbsp; Forsythe et al., "Replicability, Fairness and Pay."</P><P><A NAME=11>11</A>&nbsp; R. Mark Isaac and James M. Walker, "Group Size Effects in Public Goods Provision: The Voluntary Contribution Mechanism," <I>Quarterly Journal of Economics</I> 103 (1988): 179-200.</P><P><A NAME=12>12</A>&nbsp; Peter Kollock, "Transforming Social Dilemmas: Group Identity and Cooperation," in Peter Danielson, ed., <I>Modeling Rational and Moral Agents</I> (Oxford: Oxford University Press, 1997).</P><P><A NAME=13>13</A>&nbsp; Catherine Eckel and Philip Grossman, "Chivalry and Solidarity in Ultimatum Games," February 1997. Virginia Polytechnic Institute, Working Paper #E92-23.</P><P><A NAME=14>14</A>&nbsp; Elizabeth Hoffman et al., "Preferences, Property Rights, and Anonymity in Bargaining Games."</P><hr width=50%><P><A NAME=1a>1</A>&nbsp; Lee A. Dugatkin, <I>Cooperation Among Animals: An Evolutionary Perspective</I> (New York: Oxford University Press, 1997).</P><P><A NAME=2a>2</A>&nbsp;, <I>Cooperation</I>, p. 167; John R. Krebs and Nicholas B. Davies, <I>An Introduction to Behavioural Ecology</I> (Sunderland, Mass.: Sinauer Associates, 1981), p. 24. </P><P><A NAME=3a>3</A>&nbsp;It's worth noting that Andreoni's later work showed that about half of the cooperation seen in public goods games reflects player confusion. Andreoni, "Cooperation in Public Good Experiments: Kindness or Confusion," <I>American Economic Review</I> 85 (1995)</P></blockquote><P><CENTER><FONT SIZE="2" COLOR="#808080">Originally published in the February/ March 1998 issue of Boston Review</FONT></CENTER></P><STYLE><!--A.menu {text-decoration: none}--></STYLE> 	<DIV ALIGN=CENTER><TABLE BORDER="0" WIDTH="585">		<TR HEIGHT="36" ALIGN="CENTER" VALIGN="MIDDLE">				<TD HEIGHT="36" COLSPAN="2" NOWRAP ALIGN="CENTER" VALIGN="MIDDLE">				<BR><HR><BR>				<FONT SIZE="2" COLOR="#808080">Copyright <A HREF="mailto:bostonreview@mit.edu">Boston Review</A>, 1993-2000. All rights reserved. Please do not reproduce without permission.</FONT>				<BR><BR>				</TD>		</TR>		<TR HEIGHT="24" ALIGN="CENTER" VALIGN="MIDDLE" BGCOLOR="#CCCCCC">				<TD HEIGHT="24" COLSPAN="2" NOWRAP><FONT SIZE="2"><IMG SRC="http://bostonreview.mit.edu/images/orangedot.GIF" WIDTH="15" HEIGHT="5" BORDER="0" ALT=" | "><A HREF="http://bostonreview.mit.edu/" CLASS="menu">home</A><IMG SRC="http://bostonreview.mit.edu/images/orangedot.GIF" WIDTH="15" HEIGHT="5" BORDER="0" ALT=" | "><A HREF="http://bostonreview.mit.edu/ndf.html" CLASS="menu">new democracy forum</A><IMG SRC="http://bostonreview.mit.edu/images/orangedot.GIF" WIDTH="15" HEIGHT="5" BORDER="0" ALT=" | "><A HREF="http://bostonreview.mit.edu/fiction.html" CLASS="menu">fiction,</A> <A HREF="http://bostonreview.mit.edu/onfilm.html" CLASS="menu">film,</A> <A HREF="http://bostonreview.mit.edu/poetry.html" CLASS="menu">poetry</A><IMG SRC="http://bostonreview.mit.edu/images/orangedot.GIF" WIDTH="15" HEIGHT="5" BORDER="0" ALT=" | "><A HREF="http://bostonreview.mit.edu/archives.html" CLASS="menu">archives</A><IMG SRC="http://bostonreview.mit.edu/images/orangedot.GIF" WIDTH="15" HEIGHT="5" BORDER="0" ALT=" | "><A HREF="http://bostonreview.mit.edu/mailing_list.html" CLASS="menu">mailing list</A><IMG SRC="http://bostonreview.mit.edu/images/orangedot.GIF" WIDTH="15" HEIGHT="5" BORDER="0" ALT=" | "><A HREF="http://bostonreview.mit.edu/masthead.html" CLASS="menu">masthead</A><IMG SRC="http://bostonreview.mit.edu/images/orangedot.GIF" WIDTH="15" HEIGHT="5" BORDER="0" ALT=" | "><A HREF="#" =";" CLASS="menu" ONMOUSEOVER="status='Subscribe today, just $17 per year!'; return true;" ONMOUSEOUT="status" ONCLICK="window.open('http://bostonreview.mit.edu/subscribe_light.html','popup','toolbar=no,location=no,directories=no,status=no,menubar=no,scrollbars=yes,resizable=yes,width=375,height=270'); return true">subscribe</A><IMG SRC="http://bostonreview.mit.edu/images/orangedot.GIF" WIDTH="15" HEIGHT="5" BORDER="0" ALT=" | ">			</FONT></TD>		</TR></TABLE><BR>				<A HREF="http://bostonreview.mit.edu/.click?http://www.blacksparrowpress.com" TARGET="_blank">	<IMG SRC="http://bostonreview.mit.edu/images/ads/blacksparrow.gif" alt="Advertisement: Black Sparrow Press"  ALIGN=TOP WIDTH="455" HEIGHT="60" BORDER="0"></A>	</DIV></BODY></HTML>
