ID=G0097
URL=http://www.nap.edu/readingroom/books/cosmology/4.html
SIZE=28747
DATE=09/07/2002
TIME=16:15:59
DATASET=Astronomy
HTML=
<HTML>

<HEAD>

<TITLE>Cosmology: A Research Briefing</TITLE>

<META NAME="GENERATOR" CONTENT="Internet Assistant for Microsoft Word 2.0z">
</HEAD>
<BODY BGCOLOR="#FFFFFF">

<P>
<CENTER><B>Cosmology: A Research Briefing</B> </CENTER>
<HR>

<H2><A NAME="TDU">IV. THE DISTANT UNIVERSE</A> </H2>

<H3><A NAME="MtCParams">Measuring the Cosmological Parameters</A>
</H3>

<P>
We have known since the late 1920s that the universe is expanding.
Quantifying the expansion is done conventionally in terms of two
numbers. <I>H</I><SUB>0</SUB>, the Hubble constant, measures the
current expansion rate of the universe, and <I>q</I><SUB>0</SUB>
is the rate at which the expansion is slowing, or decelerating,
because of the self-gravitational pull of all the matter in the
universe. The standard cosmological solutions of Einstein's equations
of general relativity are specified by <I>H</I><SUB>0</SUB> and
<I>q</I><SUB>0</SUB>. <I>H</I><SUB>0</SUB><SUP>-1</SUP>, the inverse
of the Hubble constant, is a measure of the current age of the
universe, while <I>q</I><SUB>0</SUB> is a measure of how long
the universe will continue to expand. 
<P>
Two additional quantities that affect the expansion are the cosmological
constant, , the vacuum energy density of the universe, and , the
ratio of the total mass/energy density in the universe to the
critical density, which is required to just bring the expansion
to a halt in the infinite future. Consider first the case where
<FONT FACE="Symbol">L</FONT>&nbsp;=&nbsp;0. If <FONT FACE="Symbol">W</FONT>
&lt; 1, the self-gravity of the universe is insufficient ever
to stop its expansion (an &quot;open&quot; universe). If <FONT FACE="Symbol">W</FONT>
&gt; 1, the expansion will eventually stop and the universe will
collapse (a &quot;closed&quot; universe). 
<P>
The term represents a strange phenomenon. As noted, it measures
the energy density of a vacuum, which remains constant as the
universe expands, unlike ordinary matter and radiation whose densities
decrease with expansion. A non-zero vacuum energy density would
mean that energy is present in an empty universe even in the absence
of particles or radiation. Though it seems odd, such a possibility
is consistent with Einstein's theory of gravitation. The key point
about <FONT FACE="Symbol">L</FONT> is that such energy generates
gravity even without normal matter or radiation--hence, gravity
from a vacuum. Because of this phenomenon, and because <FONT FACE="Symbol">L</FONT>
remains constant as the universe expands (a vacuum cannot be diluted),
the existence of non-zero <FONT FACE="Symbol">L</FONT> radically
changes the dynamics of the universe. This is the key concept
that underlies inflation, which is discussed in section V. If
there is currently no vacuum energy density in the universe, then
<FONT FACE="Symbol">L</FONT> &nbsp;=&nbsp;0 and <I>q</I><SUB>0</SUB>&nbsp;=
<FONT FACE="Symbol">W</FONT>/2; most cosmologists believe that
<FONT FACE="Symbol">L</FONT> is 0, but understanding why it is
so small is a profound question of fundamental physics.
<H4><A NAME="HC">The Hubble constant, H<SUB>0</SUB></A> </H4>

<P>
The Hubble constant measures how fast the universe is expanding
today. In addition, the age of the universe can be expressed as
approximately (2/3)<I>H</I><SUB>0</SUB><SUP>-1</SUP> (the precise
value depends on and ). The accurate determination of <I>H</I><SUB>0</SUB>
has occupied astronomers for several decades, and the scientific
motivation for finding an accurate value of this critical constant
has become ever stronger. Another key use of <I>H</I><SUB>0</SUB>
is to estimate the physical distance and size of objects that
have measurable redshifts. For example, the size of the largest
structures in the universe is related to the distance that light
could have traveled in the time up to the epoch when matter began
to dominate over radiation. The corresponding size scale today
is an important relic of the Big Bang, but its value is proportional
to <I>H</I><SUB>0</SUB><SUP>-2</SUP> and therefore suffers from
the current uncertainty. An accurate measurement of <I>H</I><SUB>0</SUB>
is crucial for assessing whether the detailed models of the evolution
of structure in the universe can be reconciled with a wide range
of observations. 
<P>
Current estimates of <I>H</I><SUB>0</SUB> range between 45&nbsp;km/s
per megaparsec (a megaparsec is about 3 million light-years) and
90 km/s per megaparsec. A value near 45 to 50 is considered low
and 80 to 90 is considered high. If <FONT FACE="Symbol">L</FONT>
=&nbsp;0 and <FONT FACE="Symbol">W</FONT> = 1 (the theoretically
preferred values for these parameters), then <I>H</I><SUB>0</SUB>&nbsp;=&nbsp;50
&nbsp;km/s per megaparsec means an age of 13.3&nbsp;billion years,
and <I>H</I><SUB>0</SUB>&nbsp;=&nbsp;90&nbsp;km/s per megaparsec
means 7.4&nbsp;billion years. A fundamental reality check comes
from requiring the oldest stars in our galaxy to be younger than
the age of the universe. This requirement, a logical necessity,
sets an upper limit to <I>H</I><SUB>0</SUB>. Astronomers' best
estimates of the age for such globular cluster stars are near
15 billion years, in conflict with the smaller value of the age
of the universe estimated by high values of <I>H</I><SUB>0</SUB>.
<P>
Ground-based facilities and techniques have improved dramatically
over the past three decades, yet <I>H</I><SUB>0</SUB> still remains
uncertain to almost a factor of two. The problem is that different
techniques and different research groups get discrepant values
for <I>H</I><SUB>0</SUB>. This is a sure sign that unknown systematic
errors exist. Which value is correct? The successful repair of
the Hubble Space Telescope (HST) has enabled that instrument to
help resolve this long-standing issue. The HST observations employ
a well-established astronomical technique that relies principally
on using Cepheid variable stars in other galaxies as &quot;standard
candles&quot; of known luminosity. The technique provides estimates
of the distance to other galaxies. The distances, together with
the recession velocities measured by the redshifts of their spectra,
permit determination of the value of <I>H</I><SUB>0</SUB>. Recent
results derived from HST observations yield a value of <I>H</I><SUB>0</SUB>
= 80 17 km/s per megaparsec, consistent with low values of the
age-below 10 billion years. The resulting conflict with estimates
for globular cluster ages may emerge as one of the most exciting
cosmological questions of the next decade. Solving this problem
could require major changes to stellar evolution theory, or even
non-zero values for&nbsp;<FONT FACE="Symbol">L</FONT>. 
<P>
The planned refurbishment of the HST with a new, advanced camera
in 1999 should enable it to make an even more accurate calibration
of the cosmic distance scale and a more definitive measurement
of the Hubble constant. However, because of the critical conflict
between the estimated ages, it is clearly vital to verify the
HST value by alternative, independent means. These include methods
based on the detailed study of supernova atmospheres, the attenuation
of CMBR radiation as it passes through the hot gas within galaxy
clusters (the Sunyaev-Zel'dovich effect), and the difference in
arrival time between separate components of gravitationally lensed
quasars (discussed below). All these approaches offer alternative
measurements of <I>H</I><SUB>0</SUB>. 
<H4><A NAME="DP">The deceleration parameter, </A><I>q</I><SUB>0</SUB>
</H4>

<P>
Measuring <I>q</I><SUB>0</SUB> directly requires measuring the
change in the universal expansion rate over a large range of cosmic
time. This is done using &quot;global&quot; cosmological tests
extending over large enough distances that the travel time of
light is an appreciable fraction of the age of the universe. The
basic idea is that the size and appearance of a distant patch
of the universe, as viewed from our vantage point, depends both
on how the universe expands (its global geometry) and on the bending
of light by the gravity of intervening matter. 
<P>
Extensive efforts in the 1960s and 1970s to study the apparent
luminosity or size of distant objects, such as very luminous galaxies,
were based on the hope that these objects were constant in brightness.
These efforts were mostly abandoned after it was learned that
the intrinsic luminosity of these standards probably changed significantly
with time because of galaxy evolution. Recent studies of the apparent
size of features in distant radio galaxies might provide a new
way to measure <I>q</I><SUB>0</SUB>. Direct counts of galaxies
as a function of measured redshift can also be a powerful probe
of the curvature of space-another name for <I>q</I><SUB>0</SUB>.
This test was attempted in the last decade, but again yielded
ambiguous conclusions. With improved modeling of the evolution
of galaxies and a major effort to obtain spectra of a large sample
of faint galaxies, this test might prove to be an effective way
to measure both <I>q</I><SUB>0</SUB> and . Cosmological models
with different values of <I>q</I><SUB>0</SUB> and predict different
volumes of space for a given observed redshift, and the number
of galaxies is a measure of the size of that volume. This volume
evolution affects not only the number of quasars, supernovae,
or galaxies at any redshift, but also the number of potential
gravitational lenses (discussed below). Preliminary results from
a study of quasar images with HST suggest that lensed quasars
are relatively rare. Models with large overpredict the number
of observed gravitational lenses; therefore, is not large.
<H4><A NAME="DensityParam">The density parameter, </A><FONT SIZE=4 FACE="Symbol">W</FONT>
</H4>

<P>
Without going to cosmological distances, it is possible to measure
the density parameter , by means of so-called local tests. Many
of the local tests &quot;weigh&quot; local structures by applying
the virial theorem, which states that the kinetic energy of a
self-gravitating system should be approximately equal to its potential
energy. Since the motion of luminous galaxies must be observed
to estimate the kinetic energy of the system, only the component
of the mass density clustered with luminous galaxies can be examined
in this fashion. As noted earlier, such measurements tend to give
low values of <FONT FACE="Symbol">W</FONT>, around 0.1 to 0.2.
However, as mentioned in the discussion of cosmic velocity flows
in section III, there may be a component of dark matter clumped
in sizes larger than clusters of galaxies but smaller than superclusters.
Cosmic velocity flows may be detecting structures on this scale,
giving values of <FONT FACE="Symbol">W</FONT> near 1. If there
exists a perfectly smooth background of mass density unclustered
with the galaxy distribution on any scale, it can be detected
only by its effects on the curvature of space, in the global measurements
of <I>q</I><SUB>0</SUB>.
<H3><A NAME="DIG">Deep Imaging of Galaxies</A> </H3>

<P>
Galaxies have been used as beacons to map the distribution of
matter in the universe ever since they were recognized as independent
systems of stars. As described above, the &quot;local&quot; distribution
of galaxies shows a complicated network of structures. When averaged
over the largest distances, many billions of light-years, the
distribution of matter is expected to be more homogeneous. Current
research programs on very distant galaxies have two distinct goals.
The first is to use the number of visible galaxies as a measure
of the surveyed volume. If galaxies were stationary and the geometry
of space were determined by the rules of euclidean geometry, then
the number of galaxies seen would be roughly proportional to the
cube of the distance probed (<I>N</I> <I>r</I><SUP>3</SUP>). When
the effects of redshift and non-euclidean geometry are taken into
account, the number of galaxies is expected to increase more slowly
than <I>r</I><SUP>3</SUP> at larger distances, as is indeed observed.
(If these effects were not present, the night sky would not be
dark! This is known as Olbers's paradox.) Questions about the
geometry of the universe-is space positively or negatively curved,
infinite or finite?-can be related by general relativity to the
dynamics of the expansion (will the universe expand forever, or
will it stop expanding and collapse in a Big Crunch?). Thus, measuring
the curvature of the universe in the past can be used to predict
the expansion of the universe in the future.
<P>
The second use of distant galaxies is to probe for signs of evolution
of galaxies and of the clustering of galaxies in the universe
over the billions of years during which their light has been traveling
to us. The notion is that a galaxy seen at an earlier stage in
its life should have more gas available out of which to form new
stars, and consequently it should appear brighter and bluer (when
adjusted for redshift) because of the presence of many massive,
hot young stars. A trend to bluer colors in fainter galaxies has
been detected, and its detailed interpretation is a subject of
active current research. 
<H3><A NAME="EoLSSBiT">Evolution of Large-Scale Structure Back
in Time</A> </H3>

<P>
Since density fluctuations tend to grow, the amplitude of the
density variations associated with the large-scale structure must
have been smaller when the universe was younger. The unique capability
of large telescopes to look deep into space corresponds to being
able to look back in time-cosmologists can map the distant universe
and see the galaxy distribution as it was billions of years ago.
By comparing different depths in space, cosmologists can in effect
&quot;make a movie&quot; of the developing structure. Successive
scenes in the movie are first galaxy formation, then cluster formation,
and finally superclustering today. Present optical and x-ray data
hint strongly that clustering in the universe continues to grow
rapidly, but these observations are still primitive. The evolution
of galaxies and large-scale structure is a sensitive probe of
alternative models of structure formation, but one that has been
little utilized to date. With the completion of giant new optical
telescopes (such as the Keck (<A HREF="#Fig5">Figure 5</A>), the
Gemini, and other large telescopes under construction), as well
as the refurbishment of the HST with a new, advanced camera, progress
in this important field should accelerate. 
<P>
Looking all the way back to a time when the universe was only
a quarter of its present age requires maximum light-gathering
power since very distant galaxies must be observed. There are
several requirements for such studies-the largest possible optical-infrared
telescopes with wide fields of view; spectrographs capable of
measuring many galaxies simultaneously; the largest possible optical
CCDs and infrared array detectors; and deep surveys in other wavelengths,
including radio and x-ray regions. 
<H3><A NAME="SQALSPfCosmo">Supernovae, Quasars, and Absorption
Line Systems: Probes for Cosmology</A> </H3>

<P>
In a closed cosmological model (e.g<I>.</I>, <I>q</I><SUB>0</SUB>&nbsp;<FONT FACE="Symbol">&#179;</FONT>&nbsp;0.5,
<FONT FACE="Symbol">L</FONT>&nbsp;=0 ), space is positively curved
and finite. A two-dimensional analog is the curved and finite
surface of a sphere. In an open model, space is negatively curved
and infinite. A two-dimensional analog is a hyperboloid, which
is shaped like a saddle. At a given redshift, sources of the same
intrinsic luminosity appear to be larger and brighter in a closed
universe than in an open universe, because of the focusing effects
of the curvature and the more rapid deceleration. Astronomers
endeavor to identify and employ classes of bright sources of known
or calculable luminosity as &quot;standard candles.&quot; By measuring
the apparent luminosity at various redshifts of these sources,
cosmologists can determine whether the universe is closed or open.
Supernova explosions provide sources of this kind because their
intrinsic brightness is governed by the physics of the explosion,
of which there is good theoretical understanding. <BR>
<BR>

<P>
<CENTER><A NAME="Fig5"><IMG SRC="fig5.gif"></A><BR>
<BR>
<BR>
</CENTER>
<P>
<CENTER><TABLE BORDER=3>
<TR><TD WIDTH=378><FONT SIZE=2>Figure 5. The first Keck telescope, atop Mauna Kea, Hawaii. This 10-m-diameter optical telescope is the first in a new generation and will be joined by the second Keck telescope. </FONT>
</TD></TR>

</TABLE>
</CENTER>
<P>
Quasars are star-like objects with large redshifts and inferred
luminosities that are often hundreds of times those of normal
galaxies. They are thought to occur in the nuclei of galaxies,
but the conditions required for a galaxy to harbor a quasar are
not known. Quasars show strong evolution in the sense that they
emitted much more energy at earlier cosmic epochs, but why this
is so is also unknown. Moreover, the observed rapid variation
in brightness of individual quasars is not understood. The task
of understanding the nature and origin of quasars is still at
the forefront of cosmological research.
<P>
Quasars can serve as background lamps against which absorption
from intervening material can be detected spectroscopically. The
material may be in the form of gas in galaxies (the galaxy itself
may or may not be visible) or in the form of intergalactic clouds
of gas that have never been processed through stars. The technique
has exceptionally high sensitivity to small amounts of material,
and so it provides a probe of the universe that is independent
and complementary to that provided by visible galaxies. The change
in the average number of absorbers as a function of redshift is
an important diagnostic for understanding the evolution of these
objects. Spectroscopic attributes of the absorbers can tell us
about their physical properties as well as the intensity and spectrum
of the intergalactic radiation falling on them. 
<P>
These absorption studies have shown that the absorbing gas occurs
in lumps, and that there is little neutral hydrogen in a smoothly
distributed intergalactic medium. One explanation of this lack
of neutral hydrogen is that, at some point, the entire universe
was reionized--heated so hot that hydrogen atoms were broken up
into their constituent protons and electrons. But if the universe
was reionized, what were the heating agents and when did the reionization
occur? On the other hand, if there was no epoch of reionization,
what conditions yielded such high efficiency in clearing intergalactic
space of neutral hydrogen? This field will be advanced with the
further identification of close pairs of quasars to provide nearly
coincident lines of sight, as well as the further identification
of galaxies likely to be responsible for individual absorption
systems. At present these absorption lines provide one of our
only probes of nonluminous structure at high redshift. Continued
theoretical as well as observational studies provide our best
hope for an accurate picture of the intergalactic medium and its
evolution. 
<H3><A NAME="GLs">Gravitational Lenses</A> </H3>

<H4><A NAME="Waglawati">What are gravitational lenses, and why
are they important?</A> </H4>

<P>
The gravitational lens is a relatively newly discovered phenomenon
that is emerging as an important research tool in cosmology. Lensing
can be produced when light propagating through the universe is
deflected by the gravitational field of a massive object positioned
near its path. Gravitational lensing effects are similar to those
produced when a glass lens deflects the path of light rays in
a camera, but the deflections are too small to be observed in
a terrestrial laboratory. However, in 1979 the discovery of a
double quasar, which was actually twin images of the same quasar,
provided the first convincing demonstration that gravitational
lensing produces observable effects in the cosmos. 
<P>
Gravitational lensing has been observed in several forms. There
are now approximately 20 known cases of strong lenses in which
two or more images of a background source are produced by a foreground
gravitational lens. This striking phenomenon is the most easily
recognized, and early work in gravitational lensing concentrated
on the study of strong lensing. <A HREF="#Fig6">Figure 6</A> shows
an Einstein cross, a lens that produces four multiple images of
a distant quasar with a central object. Another manifestation
is weak lensing, in which background sources, though not multiply
imaged, are visibly distorted by the presence of the intervening
gravitational field (<A HREF="#Fig7">Figure 7</A>). Changes in
the gravitational field, produced for example by relative motion
of the source and the lens, have been observed through the changes
in the magnification of the source that produce variations in
the source brightness. The multiple images found in strong lenses
are associated with different propagation times from source to
observer, and the resulting time delay between the arrival times
of signals from each image has also been observed. In the best
studied case, the measured time delay from one image to the other
is approximately 1.5 years. Finally, the presence of a population
of massive objects, such as galaxies, screening a population of
background sources, such as quasars, produces lensing effects
detectable through statistical analysis of the ellipticities of
the lensed images.<BR>
<BR>

<P>
<CENTER><A NAME="Fig6"><IMG SRC="fig6.gif"></A> <BR>
<BR>
</CENTER>
<P>
<CENTER><TABLE BORDER=3>
<TR><TD WIDTH=378><FONT SIZE=2>Figure 6. The image of an Einstein cross produced by a gravitational lens 2237+0305. A distant quasar is precisely aligned behind the foreground galaxy whose gravitational field deflects the light from the quasar into four distinct images. (Courtesy of the Space Telescope Science Institute.)</FONT> 
</TD></TR>

</TABLE>
</CENTER>
<P>
Gravitational lenses provide a unique opportunity to infer the
properties of the space-time in which they are embedded, the mass
distribution of the lens, and the detailed properties of the background
source. These opportunities are being realized as instruments
improve in angular resolution and sensitivity, as our data-handling
capabilities grow, and as increased computational capacity can
be applied to theoretical analyses of lenses.<BR>
<BR>

<P>
<CENTER><A NAME="Fig7"><IMG SRC="fig7.gif"></A><BR>
<BR>
<BR>
</CENTER>
<P>
<CENTER><TABLE BORDER=3>
<TR><TD WIDTH=503><FONT SIZE=2>Figure 7. Gravitational lensing of distant background galaxies by the potential well of a foreground cluster of galaxies. The distinctive arcs are a result of strong lensing in which the images formed by the lens encircle the optical axis of the system. (Courtesy of Space Telescope Science Institute.)</FONT>
</TD></TR>

</TABLE>
</CENTER>
<H4><A NAME="MCPwGLs">Measuring cosmological parameters with gravitational
lenses</A> </H4>

<P>
Because the light rays in a gravitational lens system propagate
across large distances, their interpretation is subject to assumptions
about the cosmological model. Observations of gravitational lenses
therefore provide a way to measure or constrain the cosmological
parameters <I>H</I><SUB>0</SUB>, <I>q</I><SUB>0</SUB>, <FONT FACE="Symbol">L</FONT>
and described above. The Hubble constant is most directly inferred
through a measurement of the time delay in the arrival of signals
from the multiple images of a strong gravitational lens. The success
of this technique is predicated on a precise understanding of
the distribution of the matter in the lens, which must be reconstructed
purely from the properties of the images. The statistics of gravitational
lenses provide a powerful technique for the determination of cosmological
parameters. For example, the frequency of occurrence of gravitational
lenses depends strongly on the geometry of the universe. A high-redshift
quasar is twice as likely to be gravitationally lensed in a <I>q</I><SUB>0</SUB>
= 0 universe as in a <I>q</I><SUB>0</SUB> = 0.5 universe. Similarly,
a high-redshift quasar is about 15 times more likely to be strongly
lensed in a flat universe if <FONT FACE="Symbol">L</FONT>&nbsp;=&nbsp;1
than if <FONT FACE="Symbol">L</FONT>&nbsp;=&nbsp;0. Current limits
appear to preclude models in which the term dominates the universe;
improved constraints will be possible with improved imaging using
the newly completed Very Long Baseline Array (VLBA), the HST,
and ground-based optical telescopes equipped with adaptive optics
systems. 
<P>
Gravitational lensing, along with the spectroscopic absorption
studies of intergalactic clouds, is one of the few techniques
in cosmology in which our ability to detect the presence of matter
does not require that the matter be luminous. Lensing can address
the important issues of the nature and the distribution of dark
matter on a wide range of scales. For example, the measurement
of weak lensing, in which faint background galaxies would be expected
to have correlated orientations due to the gravitational distortions
induced by the foreground mass distribution, can be studied by
careful analysis of high-quality images covering large fields
of view. Recent theoretical analysis describes how this method
can provide a solid measurement of the matter-clustering amplitude
of the foreground mass distribution. Elongated images are more
likely to occur near large concentrations of matter, such as clusters
of galaxies, where several spectacular examples have already been
observed (see <A HREF="#Fig7">Figure 7</A>). 
<P>
On small scales (stellar masses or smaller), the most effective
technique is observation of microlensing, the variations in flux
detected from a background source due to the focusing of rays
caused by the passage of a massive object through the beam. By
searching for microlensing events in the direction of nearby concentrations
of stars, three separate research groups have found spectacular
examples of large flux amplification (up to a factor of 14!).
These events might imply that the dark matter comprising the halo
of our galaxy is dominated by compact stars that were never sufficiently
massive to ignite their nuclear furnaces and become luminous,
or that there exist many more remnants of normal stars in an extended
disk of our galaxy than had been anticipated. The time behavior
of one well-documented microlensing event in the direction of
the nearby Large Magellanic Cloud is shown in <A HREF="#Fig8">Figure 8</A>.
<P>
The study of gravitational lensing has already provided important
results in cosmology. Improved instrumentation and data-handling
techniques are allowing astrophysicists to recognize and exploit
subtle manifestations of gravitational lensing, as well as the
striking examples of strong lensing. With the planned capabilities
of future generations of instruments, and the growing interest
in gravitational lensing as an observational tool, it is likely
that this trend will continue. <BR>
<BR>

<P>
<CENTER><A NAME="Fig8"><IMG SRC="fig8.gif"><BR>
<BR>
<BR>
</A></CENTER>
<P>
<CENTER><TABLE BORDER=3>
<TR><TD WIDTH=378><FONT SIZE=2>Figure 8. The first well-documented microlensing event, detected when a faint object of approximately 0.1 solar mass crossed very close to the line of sight between Earth and a star in the Large Magellanic Cloud (LMC). The gravitational lensing caused by the object has focused and intensified the light detected from an LMC star in the background, causing the peak in the brightness at both blue (A<SUB>blue</SUB>) and red (A<SUB>red</SUB>) wavelengths recorded as a function of time. (Courtesy of Charles Alcock for the MACHO Project.)</FONT>
</TD></TR>

</TABLE>
</CENTER>
<P>
<BR>

<HR>

<P>
<CENTER><A href="3.html"><FONT SIZE=2>Previous Section</FONT></A><FONT SIZE=2>
| <A href="http://www.nap.edu/readingroom/books/cosmology/">HTML Home Page</A>
| <A href="http://www.nas.edu">NAS Home Page</A> | <A href="http://www.nap.edu">NAP Home Page</A>
<BR>
<A href="5.html">Next Section</A> | <A href="http://www.nap.edu/readingroom">Reading Room</A>
| <A href="http://www.nap.edu/readingroom/enter2.cgi?NX005722.html">Report Home Page</A>
</FONT></CENTER>
<HR>

</BODY>

</HTML>

