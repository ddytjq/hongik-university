ID=H0314
URL=http://www.lecb.ncifcrf.gov/~toms/bionet.info-theory.faq.html
SIZE=63486
DATE=11/07/2002
TIME=17:03:47
DATASET=Biology
HTML=<!-- REMOVE LINE FOR CREATING FLAT FILE FOR POSTING
Subject: Biological Information Theory and Chowder Society FAQ
Newsgroups: bionet.info-theory,news.answers
Followup-To: bionet.info-theory
Keywords: FAQ, Biological Information Theory and Chowder Society
Approved: news-answers-request@MIT.Edu
Archive-name: biology/info-theory
REMOVE LINE FOR CREATING FLAT FILE FOR POSTING-->

<html>
<title>bionet.info-theory FAQ</title>

<body
bgcolor="#D9D9F3"
text="#000000"
link="#0000ff"
alink="#00ff00"
vlink="#ff0000"
>

<a href = "http://www.lecb.ncifcrf.gov/~toms/bitcs.html">
<IMG SRC="http://www.lecb.ncifcrf.gov/~toms/icons/chowdersoup-small.jpg"
align = right ALT = "Campbell's Chowder Soup Can"></a>

<h1 align="center">
Frequently Asked Questions (FAQ) for bionet.info-theory<br>
Biological Information Theory and Chowder Society</h1>

<h4 align="center">
version = 2.29 of bionet.info-theory.faq.html 2001 August 28
<br> 

<p>
<a href="http://www.lecb.ncifcrf.gov/~toms/bionet.info-theory.faq.html">
http://www.lecb.ncifcrf.gov/~toms/bionet.info-theory.faq.html</a>
</p>

</h4>

<hr>

<h2>Summary: </h2>

<p>
This is the Frequently Asked Questions monthly posting for BITCS.  The news
group bionet.info-theory is a forum for discussing information theory in
biology and for tossing food for thought around.  Other interesting
mathematical problems in biology are also welcome, as we will try our best to
take the log of them, so as to convert them into information theory
problems.
</p>

<p>
<h2>*** NEWCOMERS PLEASE NOTE:</h2>
</p>

<p>
  Although the name of this group,
bionet.info-theory has the word "info" in it, this newsgroup is NOT an
appropriate forum for persons seeking information about general questions
related to biology or medicine!  This newsgroup is devoted to DISCUSSIONS
ABOUT BIOLOGICAL APPLICATIONS OF INFORMATION THEORY, principally referring to
Shannon's theory of information, although we also discuss the mathematical
and physical meaning of entropy, alternative definitions of information, and
related fundamental issues in information theory and biology.
</p>

<p>
<hr>
</p>

 <ul>
 <li>
 <h3>Questions about The BITCS, the newsgroup, and this FAQ</h3>
<p>
   <ul>
   <a href="#What.is.The.BITCS">

    <li>What is The Biological Information Theory and Chowder Society?</a><br>

   <a href="#bionet.info-theory.BY.EMAIL">
   <li>How Do I obtain bionet.info-theory BY EMAIL?</a><br>

   <a href="#Where.Did.I.Get.This.FAQ">
   <li>Where Did I Get This FAQ File Originally?</a><br>

   <a href="#IP.number.of.the.FAQ">
   <li>What is the IP number of the FAQ archive?</a><br>

   <a href="#Bionet.Archives">
   <li>Where Are the Bionet Archives?</a><br>

   <a href="#Other.Archives">
   <li>Are There Other Archives?</a><br>

   <a href="#Posted.But.Nothing.Happened">
   <li>I Posted But Nothing Happened?!?</a><br>

   <a href="#Appropriate.Postings">
   <li>What is an Appropriate Posting?</a><br>

   <a href="#Inappropriate.Postings">
   <li>What Can I Do About Inappropriate Postings?</a><br>

   <a href="#Private.email">
   <li>Should I send private email to someone
        to respond to a posting or to ask a question?</a><br>

   <a href="#copyright">
   <li>What is the official word on copyright of this FAQ?</a><br>

   <a href="#Who.Takes.Care.of.This.Group">
   <li>Who Takes Care of This Group?</a><br>

   <a href="#Kind.of.Questions">
   <li>What Kind of Questions Are Appropriate For Discussion?</a><br>

   <a href="#When.and.Where.are.Meetings">
   <li>
When and Where are Meetings?</a><br>

   <a href="#Acknowledgments">
   <li>Acknowledgments</a><br>

   </ul>
 </p>

 <p>
 <li>
 <h3>Questions about Information Theory</h3><p>

  <ul>

  <a href="#What.is.IT">
  <li>What is Information Theory?</a><br>

  <a href="#Quick.Introduction">
  <li>Is There a Quick Introduction to Information Theory Somewhere?</a><br>

  <a href="#Information.Equal.Entropy"> 
  <li>I'm Confused: How Could Information Equal Entropy?</a><br>

  <a href="#Learn.More.About"> 
  <li>How Can I Learn More About Information Theory and Biology?  References</a><br>

  <ul>

   <a href="#REFERENCES-General">
   <li>REFERENCES - General</a>

   <a href="#REFERENCES-Information_Theory">
   <li>REFERENCES - Information Theory</a>

   <a href="#REFERENCES-Jaynes">
   <li>REFERENCES - Jaynes</a>

   <a href="#REFERENCES-Schneider">
   <li>REFERENCES - Schneider</a>

   <a href="#REFERENCES-Yockey">
   <li>REFERENCES - Yockey</a>

   <a href="#REFERENCES-Adleman">
   <li>REFERENCES - Adleman and papers related to molecular computation</a>

   <a href="#REFERENCES-Yagil">
   <li>REFERENCES - Gad Yagil and papers related to Algorithmic Information
   Theory (AIT) or Algorithmic Complexity</a>

   <a href="#REFERENCES-entropy-www">
   <li> REFERENCES - Entropy on the World Wide Web</a>
<!-- REFERENCES - Chris Hillman and papers related to entropy -->

   </ul>

   <a href="#Send.Me.Papers">
   <li>Will Authors Send Me Papers?</a><br>

   <a href="#BIG.Coins">
   <li>Where Can I Get BIG Coins?</a><br>

   <a href="#other.orgs"> 
   <li>Are there other organizations for information theory?</a><br>

   <a href="#Sequence.Logos"> 
   <li> What are Sequence Logos?</a>

     <ul>

    <a href="#Sequence.Logos.on.the.Web"> 
     <li>How Do I find Sequence Logos on the Web?</a><br>

    <a href="#Shell.Script.for.Making.Sequence.Logos">
     <li>Is There a Shell Script for Making Sequence Logos?</a><br>

    <a href="#Web.Page.for.Making.Sequence.Logos">
     <li>Is There a World Wide Web Page for Making Sequence Logos?</a><br>

  </ul>

 </ul> 
 </ul>

<p>
<h3 align=center><a name="What.is.The.BITCS">
<hr>
What is The Biological Information Theory and Chowder Society?
</a></h3>

<p>
The Biological Information Theory and Chowder Society (BITCS) is a group of
scientists interested in the biological applications of information theory
(thus the "BIT") who meet informally for dinner (thus the "CS") from time to
time in the Washington, DC, area.  At our dinners we have only one rule ---
food fights are discouraged.
</p>

<p>
The guys who started this thing did it because we weren't certain we
understood the biological implications of information theory.  Some of us are
more comfortable with the mathematical machinery and assemble biological
systems into grand canonical ensembles whether they want to be there or not;
and some of us think they understand what the biological systems are doing
but can't take a log to base 2.  What we try to do is pry from one another
the bits of knowledge that will help us understand what's going on.
</p>

<p>
Some of the topics up for discussion in our group are:

<p>
<ul>
 <li>biological applications of information theory
 <li>biochemical molecular machines and computers
 <li>computer methods for recognition of molecular structure and function
 <li>database organization for biomolecular information
 <li>nanotechnology
 <li>the limits of computation
 <li>"dissipation-less"(?) computation
 <li>Maxwell's demon
 <li>anecdotes and humor about all these topics
 <li>methods and theories of molecular computation
 <li>macroscopic versus microscopic thermodynamics
</ul>
</p>

<p>
A few relevant papers are given
in the
<a href="#REFERENCES-General">references</a>.
</p>

<p>
The group started when Tom Schneider was introduced to John Spouge in 1988.
Tom bounced his ideas about molecular machines off John, and John kept
finding flaws.  Tom would go away rather unhappily for a month and then find
a solution.  But John was always one step ahead...  (and still is, on last
account.)  Tom gave a talk about molecular machines at the Lambda Lunch
meeting on the Bethesda NIH campus, and John introduced John (Steve)
Garavelli.  We all got together with Peter Basser for dinner once in a while
to talk about information theory.  Steve brought in one of the first people
to apply information theory to biology, Hubert Yockey.  Steve Garavelli
dubbed the group the "Biological Information Theory and Chowder Society",
which it is still called.  We are known sometimes as 'chowderheads', and talk
about food fights, but so far have only had electronic food fights!  We hold
dinners in Bethesda, Maryland on random occasions.
</p>

<p>
When our informal mailing list became difficult to handle, we petitioned to
start a bionet news group.  We have held roaring discussions and look forward
to more, and everyone is welcome to join.  You can look at some of
the ancient discussions in the
<a href = "#Bionet.Archives">bionet archives</a>.
If you are
uncertain about something, quit lurking and ask on the net.  It may well be
that what bothered you is the key to a new piece of information theory in
biology.  (The major advances so far have been by things that REALLY bugged
people.)
</p>

<p>
We will also announce when and where our (irregular) eatings are and you are
welcome to join if the travel is not too far.  John Spouge
usually makes the arrangements.  If you would like
to give a talk to the group, contact us to make arrangements.
(Our addresses are
<a href="#Who.Takes.Care.of.This.Group">below</a>.)
</p>

<p>
<h3 align=center><a name="bionet.info-theory.BY.EMAIL">
<hr>
</p>

<p>
How Do I obtain bionet.info-theory BY EMAIL?
</a></h3>
</p>

<p>
If you have access to USENET news YOU DO NOT NEED AN E-MAIL SUBSCRIPTION!!
We strongly encourage all interested users to explore getting USENET news at
your site.  It's MUCH easier on you than an e-mail subscription!  Please
consult your systems manager or contact
<a href = "mailto:biosci-help@net.bio.net">biosci-help@net.bio.net</a>
for assistance if needed.
</p>

<p>
The BIOSCI (email) name for the forum is BIO-INFO.
</p>

<p>
Depending on where you are, you have to do different things to subscribe or
be removed from the email subscription list:
</p>

<p>
SUBSCRIBING / UNSUBSCRIBING
</p>

<p>
   North or South America or Pacific Rim:
</p>

<p>
Using the computer account in which you want to receive mail
messages, please send an email message to the e-mail server at
<a href = "mailto:biosci-server@net.bio.net">biosci-server@net.bio.net</a>
<br>
Leave the Subject: line blank.
In the body of the message include the line
<blockquote>
<font color = green>
     subscribe bio-info
</font>
</blockquote>
<p>
     to add yourself to the mailing list or
<blockquote>
<font color = red>
     unsubscribe bio-info
</font>
</blockquote>
to cancel an existing subscription.  If you need personal
subscription assistance, please contact
<a href = "mailto:biosci-help@net.bio.net">biosci-help@net.bio.net</a>
<p>
Europe, Africa, and Central Asia:
<p>
Send a email message to the person at
<a href = "mailto:biosci@daresbury.ac.uk">biosci@daresbury.ac.uk</a>
requesting a subscription or removal from the BIO-INFO forum.
</p>

<p>
SENDING OUT POSTINGS
</p>

<p>
Thereafter, address email messages for this forum to one of:
</p>

<p>
   North or South America or Pacific Rim:<br>
     <a href = "mailto:bio-info@net.bio.net">
      bio-info@net.bio.net</a>
</p>

<p>
   Europe, Africa, and Central Asia:<br>
     <a href = "mailto:bio-info@daresbury.ac.uk">
      bio-info@daresbury.ac.uk</a>
</p>

<p>
You can post to either of the above address if you want.  We only request
that you sign up at your local node in order to optimize the use of the
network resources for message distribution.
</p>

<p>
<font color = red>
Do not send subscription requests to any of these addresses, or you will have
sent it to everybody on the planet (to your great embarrassment, and we will
drub you with food cake)!</font>  Let me say that again:
<font color = red>
 please do not post
requests for subscription or being removed from the list to the list itself,
that takes up bandwidth all over the world!
</font>
</p>

<p>
If you have problems, contact the subscription site manager who you signed up
with.  If your problem is not resolved, please contact
<a href = "mailto:biosci-help@net.bio.net">biosci-help@net.bio.net</a>
</p>

<p>
DO NOT CONTACT TOM SCHNEIDER FOR SUBSCRIPTIONS OR UNSUBSCRIBING!
</p>

<p>
This is so complicated!
It would be a lot easier for you to use a news reader!
</p>

<p>
<h3 align=center><a name="Where.Did.I.Get.This.FAQ">
<hr>
</p>
<p>
Where Did I Get This FAQ File Originally?
</a></h3>
</p>

<ul>

<li>
The source <b>hypertext version</b> is available from<br>
<a href="http://www.lecb.ncifcrf.gov/~toms/bionet.info-theory.faq.html">
http://www.lecb.ncifcrf.gov/~toms/bionet.info-theory.faq.html</a>

<li>
The <b>flatfile</b> version of this FAQ is stored in
<a href=
"http://www.lecb.ncifcrf.gov/~toms/bionet.info-theory.faq.txt"
>http://www.lecb.ncifcrf.gov/~toms/bionet.info-theory.faq.txt</a>

<li>
A <b>PostScript version</b> is available from<br>
<a href=
"http://www.lecb.ncifcrf.gov/~toms/bionet.info-theory.faq.ps"
>http://www.lecb.ncifcrf.gov/~toms/bionet.info-theory.faq.ps</a>

<li>
A <b>PDF version</b> is available from<br>
<a href=
"http://www.lecb.ncifcrf.gov/~toms/bionet.info-theory.faq.pdf"
>http://www.lecb.ncifcrf.gov/~toms/bionet.info-theory.faq.pdf</a>

</ul>

If you are curious,
all of these alternative forms are created automatically with a csh
script called
<a href=
"http://www.lecb.ncifcrf.gov/~toms/mkbitcs"
>mkbitcs</a>
using features of netscape and
the wonderful
<a href=
"http://www.imagemagick.org"
>ImageMagick</a>.

<!--
The <b>flatfile</b>
version of this FAQ is stored in the anonymous ftp archive
ftp.ncifcrf.gov in pub/delila under the name "bionet.info-theory.faq".
The URL is:
<a href="ftp://ftp.ncifcrf.gov/pub/delila/bionet.info-theory.faq">
ftp://ftp.ncifcrf.gov/pub/delila/bionet.info-theory.faq</a>
-->

<p>
This file is posted monthly (if I remember to do it!) on
<a href="news:news.answers">news.answers</a>
and
<a href="news:bionet.info-theory">bionet.info-theory</a>.

<! This service is useless if someone already has this FAQ!
You can retrieve a copy of the FAQ by sending in the body of an email
the command
(blockquote)
      info bio-info
(/blockquote)
to (a href="mailto:biosci-server@net.bio.net")biosci-server@net.bio.net(/a).
It is possible that this version will be older than the one in the FTP
archive, so you should use this method only if you cannot use FTP.
(font color = red)
NOTE:  This service does NOT return the faq anymore, it
only returns a pointer to the flat file.
This section of the faq will be removed if 
the ability to get the flat file is not restored.
(/font)
>

<p>
Please send questions and comments to: Tom Schneider 
(<a href="mailto:toms@ncifcrf.gov">toms@ncifcrf.gov</a>).

<p>
<h3 align=center><a name="IP.number.of.the.FAQ">
<hr>
<p>
What is the IP number of the FAQ archive?
</a></h3>

<p>
For ftp.ncifcrf.gov you can use "129.43.1.11",
however, I am keeping everything on the web now.

<p>
<h3 align=center><a name="Bionet.Archives">
<hr>
<p>
Where Are the Bionet Archives?
</a></h3>

<p>
The hypertext archives for this newsgroup are at:<br>
<a href="http://www.bio.net/hypermail/BIOLOGICAL-INFORMATION-THEORY/">
  http://www.bio.net/hypermail/BIOLOGICAL-INFORMATION-THEORY/</a>
  
<p>
The entire collection of BIOSCI/bionet messages from inception are
available via the biosci.src WAIS source at net.bio.net.  Contact
<a href = "mailto:biosci-help@net.bio.net">biosci-help@net.bio.net</a>
for further help with accessing this WAIS source.
<p>

<p>
<h3 align=center><a name="Other.Archives">
<hr>
Are There Other Archives?
</a></h3>

<p>
<UL>

<p>
<LI> BIOSCI Archive of Monthly Postings.
<A HREF="ftp://net.bio.net/pub/BIOSCI/BIOLOGICAL-INFORMATION-THEORY">
         ftp://net.bio.net/pub/BIOSCI/BIOLOGICAL-INFORMATION-THEORY</A>.
This archive contains postings
from each month as a single document.
Files are in mailbox format, with
names of the form YYMM (YY=last 2 digits of the year, MM=cardinal number of
the month, zero padded).  The current months postings are in the file
'current'.
Contact
<a href = "mailto:biosci-help@net.bio.net">biosci-help@net.bio.net</a>
for further help with or comments on the archives.
For the record, the IP number for net.bio.net is [134.172.2.69].

<p>
<LI>These are the BIOSCI raw postings, just numbered:
<A HREF="ftp://net.bio.net/pub/BIOSCI/bionet/info-theory">
         ftp://net.bio.net/pub/BIOSCI/bionet/info-theory</A>

<p>
<LI>
Archive of Postings at IUBO:
<A HREF="ftp://ftp.bio.indiana.edu/usenet/bionet/info-theory/">
         ftp://ftp.bio.indiana.edu/usenet/bionet/info-theory/</A>.
This archive contains individual postings.
Older postings are collected by the month as a single document.
There is an index for each month.

<p>
<LI> Archive of Life Related Newsgroups
<A HREF="http://www.krl.caltech.edu/~brown/alife/news/">
         http://www.krl.caltech.edu/~brown/alife/news/</A>.
This is an incredibly nicely organized
HTML archive of links maintained by
<a href="http://www.krl.caltech.edu/~brown/">Titus Brown</A> at Caltech
(<a href="mailto:brown@krl.caltech.edu">brown@krl.caltech.edu</a>).
This archive contains individual postings.
Check it out!!

<p>
<LI>
current newsgroup articles on your own computer:
<A href=news:bionet.info-theory>bionet.info-theory</a>

<p>
<LI>
The BIOSCI home page carries all bionet news groups:
<A HREF="http://www.bio.net/">http://www.bio.net/</A>
</UL>

<p>
<h3 align=center><a name="Posted.But.Nothing.Happened">
<hr>
I Posted But Nothing Happened?!?
</a></h3>
<p>

Michael Harman (rmharman@jhu.edu)
<p>

| I attempted to post a question ... about a<br>
| month and a half ago, but never saw any response.<br>
<p>

Go to the bionet archives
<p>
<a href="http://www.bio.net/hypermail/BIOLOGICAL-INFORMATION-THEORY/">
  http://www.bio.net/hypermail/BIOLOGICAL-INFORMATION-THEORY/</a>
<p>

and search for your posting.  If your posting does not appear there within a
day it may mean that your posting never made it out of your system.  Try
again to see if it was a transient failure.  If that fails, talk to your
systems admin.  If your systems administrator is stumped, contact Dave
Kristofferson at
<a href="mailto:biosci-help@net.bio.net">biosci-help@net.bio.net</a> for
further help. You could also check by posting on misc.test (it's fun, I
promise!  :-).

<p>
<h3 align=center><a name="Appropriate.Postings">
<hr>
<p>
What is an Appropriate Posting?
</a></h3>
<p>

<p>
Name calling and libelous statements are not acceptable on this news group.
It's best to learn about
<a href ="http://rs6000.adm.fau.edu/rinaldi/net/">net etiquette
(netiquette)</a> before you post anything.

<p>
On the other hand, polite, carefully worded, even aggressive
<b>scientific criticism</b>
that specifically addresses issues <b>is encouraged</b>.  If you critique
someone's work, be willing to defend your statements, and be willing to admit
publically when you are wrong.  When ad hominem postings appear, we will
<a href = "http://www.lecb.ncifcrf.gov/~toms/lightning.bolt.html">
<i>quickly</i></a>
conclude that you
are intent on abusing us and will take appropriate, but legal,
<a href = "actions.html">actions against you</a>.

<p>
To maintain a high professional level of discussion, we encourage
all participants to identify themselves.  You do <b>not</b> need
any degrees or professional affiliation to join the conversation,
and you should not hesitate to post
if you feel you have something
worthwhile to contribute.

<p>
However, if you want to avoid looking naive,
some knowledge about basic molecular
biology and information theory also helps
(see
<a href ="#Learn.More.About">the references</a>), but we don't
expect you to be an expert on everything.
Also, to make a good impression on others, trim any text you copy from
previous postings, run your text through a spell checker, and use proper
English.

<p>
<h3 align=center><a name="Inappropriate.Postings">
<hr>
What Can I Do About Inappropriate Postings?
</a></h3>
<p>

The short form of this news group's name, bio-info, can be confusing to some
people inexperienced in network communications or with little knowledge of
the discipline (if there is any :-) of biological information theory.  It can
and has been mistaken as a news group for general biological information.
Our readers should be aware that when such postings come to our attention,
the discussion leaders do attempt to inform, privately, the people who make
these inappropriate postings of the error of their ways and suggest
alternative or more appropriate venues.
<p>

Subjecting the writers of inappropriate posting to public excoriation is not
a good policy because it may be an inadvertent mistake and follow-up postings
will only add to the irritation of our regular readers.  When others publicly
reply to such posts in this news group, although they may think they are
being polite to the original poster, they are still annoying our regular
readers.  We suggest that a better policy for readers who do wish to reply to
inappropriate posts is to do so privately or to an appropriate news group.
<p>

If you have nothing better to do with your time and feel you must reply to an
inappropriate posting, either because you think it might be a sincere though
misguided request for information, or because you want to express your
opinions on the poster's ancestry, cool your jets one minute and carefully
consider the poster's address.  Look in the mail header for the "From:" line,
the "Reply-to:" line, the "Message-id:" line, and the "Posting-Host:" line.
If the "From:" or "Reply-to:" lines contain obviously forged information,
like

<p>
  From: Anonymous@net.bio.net (Unknown)<br>
  Reply-to: No.one.@net.bio.net

<p>
or if the address looks legitimate but contains inconsistent node addresses
like

<p>
  From: ReadMe@ReadMe.net<br>
  Message-id: <4upgib$af8@dfw-ixnews5.ix.netcom.com>

<p>
(the part after the "@" in these two lines is not consistent), do not waste
your time.  The poster will never read your reply.  The posting is either a
"spam" or an attempt to sabotage the system whose address has been forged.

<p>
More importantly, do not waste other scientists' time and money (yes, some
people do pay for the e-mail they receive) by replying to an inappropriate
posting through the bulletin board.  No one else will be interested in seeing
your inappropriate reply to an inappropriate posting.  They may, however,
note for future reference your lack of courtesy and good judgement.

<p>
For information about how to deal with intransigent cases, see:<br>
<a href="http://math-www.uni-paderborn.de/~axel/blacklist.html">
http://math-www.uni-paderborn.de/~axel/blacklist.html</a>

<p>
For dealing with Make Money Fast schemes, see:<br>
<a href = "http://www.lecb.ncifcrf.gov/~toms/mmf.html">
http://www.lecb.ncifcrf.gov/~toms/mmf.html</a>

<p>
Another anti-spam resource is at
<a href = "http://www.canismajor.demon.co.uk/antispam/antispam.htm">
http://www.canismajor.demon.co.uk/antispam/antispam.htm</a>

<p>
<h3 align=center><a name="Private.email">
<hr>
<p>
Should I send private email to someone
to respond to a posting or to ask a question?
</a></h3>
<p>
It's fine to email someone a question or comment
about one of their postings, but remember that
you will then be holding a private conversation
with only that person and the rest of us will miss out
on your thoughts and won't be able to help you.
Of course,
private email is appropriate if you are thinking
of forming a collaboration with someone and don't
want the ideas to be public, or if you
have a technical question about the news group.
Also,
<font color = red>
please don't post <i>and</i> send email to someone
unless you have a good reason to think they will
miss the posting.
</font>
<p>
In other words, please don't email to Tom Schneider
general comments that could be public.

<p>
<h3 align=center><a name="copyright">
<hr>
<p>
What is the official word on copyright of this FAQ?
</a></h3>
<p>

This FAQ fits the description in the U. S. Copyright Act of a "United States
Government work".  It was written as a part of my official duties as
Government employee.  This means it cannot be copyrighted.  The article is
freely available without a copyright notice, and there are no restrictions on
its use, now or subsequently.  I retain no rights in the FAQ.
<p>

Thomas D. Schneider

<p>
<h3 align=center><a name="Who.Takes.Care.of.This.Group">
<hr>
<p>
Who Takes Care of This Group?
</a></h3>

<p>
Steve Garavelli <br>
Box 3783, Georgetown Station <br>
Washington, DC  20007 <br>
202-625-1907 <br>
jsgaravelli@earthlink.net <br>
<a href =
"http://home.earthlink.net/~jsgaravelli/"
>http://home.earthlink.net/~jsgaravelli/</a>
</p>

<p>
Tom Schneider<br>
National Cancer Institute<br>
Laboratory of Experimental and Computational Biology<br>
Frederick, Maryland  21702-1201<br>
<a href="mailto:toms@ncifcrf.gov">toms@ncifcrf.gov</a><br>
<a href="http://www.lecb.ncifcrf.gov/~toms/">
http://www.lecb.ncifcrf.gov/~toms/</a><br>
</p>

<p>
John L. Spouge<br>
National Center for Biotechnology Information<br>
National Library of Medicine<br>
Bethesda, MD  20894<br>
<a href="mailto:spouge@ncbi.nlm.nih.gov">spouge@ncbi.nlm.nih.gov</a><br>
<a href =
"http://www.ncbi.nlm.nih.gov/CBBresearch/Spouge/"
>http://www.ncbi.nlm.nih.gov/CBBresearch/Spouge/</a>
</p>

<p>
Please email comments and suggestions on this faq sheet to Tom.
</p>

<p>
John Garavelli (who also answers to "Steve" if you want to avoid confusion)
often organizes dinner speakers.
</p>

<p>
John Spouge often arranges dinner locations.
</p>

<p>
<h3 align=center><a name="Kind.of.Questions">
<hr>
<p>
What Kind of Questions Are Appropriate For Discussion?
</a></h3>
<p>

This faq sheet answers simple questions about this group.  The BIG questions
should be discussed on the net, where we can all haggle over them.  Here are
a few for starters:
<p>

<ul>
 <li>What is the role of theory in biology today?
 <li>What should be the role of biological theory?

 <li>What is information?  How should it be defined?

 <li>What bothers you when you read the two papers on the theory of molecular
machines?  (It is only from the things that bother us that we can make
progress in understanding.)
(See <a href="#REFERENCES-General">references</a> below.)

 <li>What are flaws in the theory of molecular machines?

 <li>How is ATP used to drive molecular machines?

 <li>All communication systems are associated with living things, so is it true
that information theory is really a theory about living things?  Was Shannon
really a great biologist?

 <li>What does Maxwell's Demon have to do with all of this?

 <li>What are the limits of computers?

 <li>What are the limits of nanotechnology?

 <li>Can we build molecular machines and molecular computers and how would they
work?
</ul>

<p>
<h3 align=center><a name="When.and.Where.are.Meetings">
<hr>
<p>
When and Where are Meetings?
</a></h3>
<p>
Meetings are announced in the
bionet.info-theory news group.
As of 1997 September 15,
meetings and talks are announced at
the
<a href ="http://www.lecb.ncifcrf.gov/~toms/bitcs.html">Biological
Information Theory and Chowder Society</a>
web page.
If you know of are going to give a relevant talk, please
submit information to
<a href="mailto:toms@ncifcrf.gov">Tom Schneider</a>.

<p>
<h3 align=center><a name="What.is.IT">
<hr>
<p>
What is Information Theory?
</a></h3>
<p>

Information theory is a branch of mathematics concerned with the process of
making choices.  Although it has a rich history going back centuries, it was
the work of
<a href = "http://www.lucent.com/timeline/tline40b.html">Claude Shannon</a>,
published in 1948 and later, that started the
field.  The theory is powerful and has resulted in great achievements.  The
beautiful sound we enjoy from compact disks (CD's) became possible only
because of Shannon's work.  The bionet.info-theory news group was formed to
discuss the many applications of information theory to biology.  (It is not a
general information news group as some might be mislead to think.)  It is
worth at least some of your time to see why we are so excited about this
application, as it could turn your research around by sharpening your
experimental approaches.

<p>
<h3 align=center><a name="Quick.Introduction">
<hr>
<p>
Is There a Quick Introduction to Information Theory Somewhere?
</a></h3>

<p>
See the primer on information theory:
<p>
<a href="ftp://ftp.ncifcrf.gov/pub/delila/primer.ps">
ftp://ftp.ncifcrf.gov/pub/delila/primer.ps</a><br>
or<br>
<a href="http://www.lecb.ncifcrf.gov/~toms/paper/primer">
http://www.lecb.ncifcrf.gov/~toms/paper/primer<br>
</a>

<p>
<h3 align=center><a name="Information.Equal.Entropy">
<hr>
<p>
I'm Confused: How Could Information Equal Entropy?
</a></h3>

<p>
If someone says that information = uncertainty = entropy, then they are
confused, or something was not stated that should have been.  Those
equalities lead to a contradiction, since entropy of a system increases as
the system becomes more disordered.  So information corresponds to disorder
according to this confusion.

<p>
If you always take information to be a decrease in uncertainty at the receiver
and you will get straightened out:

<p>
R = Hbefore - Hafter.

<p>
where H is the Shannon uncertainty:

<p>
H = - sum (from i = 1 to number of symbols) Pi log2 Pi (bits per symbol)

<p>
and Pi is the probability of the ith symbol.  If you don't understand this,
please refer to
<a href="#Quick.Introduction">
"Is There a Quick Introduction to Information Theory Somewhere?"</a>.

<p>
Imagine that we are in communication and that we have agreed on an alphabet.
Before I send you a bunch of characters, you are uncertain (Hbefore) as to
what I'm about to send.  After you receive a character, your uncertainty goes
down (to Hafter).  Hafter is never zero because of noise in the communication
system.  Your decrease in uncertainty is the information (R) that you gain.

<p>
Since Hbefore and Hafter are state functions, this makes R a function of
state.  It allows you to lose information (it's called forgetting).  You can
put information into a computer and then remove it in a cycle.

<p>
Many of the statements in the early literature assumed a noiseless channel,
so the uncertainty after receipt is zero (Hafter=0).  This leads to the
SPECIAL CASE where R = Hbefore.  But Hbefore is NOT "the uncertainty", it is
the uncertainty of the receiver BEFORE RECEIVING THE MESSAGE.

<p>
A way to see this is to work out the information in a bunch of DNA binding
sites.

<p>
Definition of "binding":  many proteins stick to certain special spots on DNA
to control genes by turning them on or off.
The only thing that distinguishes one spot from another
spot is the pattern of letters (nucleotide bases) there.
How much information is required to define this pattern?

<p>
Here is an aligned listing of the binding sites for the cI and cro proteins
of the bacteriophage (i.e., virus) named lambda:

<p>
<pre>
alist 5.66 aligned listing of:
* 96/10/08 19:47:44, 96/10/08 19:31:56, lambda cI/cro sites
piece names from:
* 96/10/08 19:47:44, 96/10/08 19:31:56, lambda cI/cro sites
The alignment is by delila instructions
The book is from:   -101 to 100
This alist list is from: -15 to 15

                       ------                   ++++++
                       111111--------- +++++++++111111
                       5432109876543210123456789012345
                       ...............................
OL1 J02459  35599 +  1 tgctcagtatcaccgccagtggtatttatgt
    J02459  35599 -  2 acataaataccactggcggtgatactgagca
OL2 J02459  35623 +  3 tttatgtcaacaccgccagagataatttatc
    J02459  35623 -  4 gataaattatctctggcggtgttgacataaa
OL3 J02459  35643 +  5 gataatttatcaccgcagatggttatctgta
    J02459  35643 -  6 tacagataaccatctgcggtgataaattatc
OR3 J02459  37959 +  7 ttaaatctatcaccgcaagggataaatatct
    J02459  37959 -  8 agatatttatcccttgcggtgatagatttaa
OR2 J02459  37982 +  9 aaatatctaacaccgtgcgtgttgactattt
    J02459  37982 - 10 aaatagtcaacacgcacggtgttagatattt
OR1 J02459  38006 + 11 actattttacctctggcggtgataatggttg
    J02459  38006 - 12 caaccattatcaccgccagaggtaaaatagt
                                             ^
</pre>

<p>
Each horizontal line represents a DNA sequence, starting with the 5' end on
the left, and proceeding to the 3' end on the right.  The first sequence
begins with: 5' tgctcag ... and ends with ...  tttatgt 3'.  Each of these
twelve sequences is recognized by the lambda repressor protein (called cI)
and also by the lambda cro protein.

<p>
What makes these sequences special so that these proteins like to stick to
them?  Clearly there must be a pattern of some kind.

<p>
Read the numbers on the top vertically.  This is called a "numbar".  Notice
that position +7 always has a T (marked with the ^).  That is, according to
this rather limited data set, one or both of the proteins that bind here
always require a T at that spot.  Since the frequency of T is 1 and the
frequencies of other bases there are 0, H(+7) = 0 bits.  But that makes no
sense whatsoever!  This is a position where the protein requires information
to be there.

<p>
That is, what is really happening is that the protein has two states.  In the
BEFORE state, it is somewhere on the DNA, and is able to probe all 4 possible
bases.  Thus the uncertainty before binding is Hbefore = log2(4) = 2 bits.
In the AFTER state, the protein has bound and the uncertainty is lower:
Hafter(+7) = 0 bits.  The information content, or sequence conservation, of
the position is Rsequence(+7) = Hbefore - Hafter = 2 bits.  That is a
sensible answer.  Notice that this gives Rsequence close to zero outside the
sites.

<p>
If you have uncertainty and information and entropy confused, I don't think
you would be able to work through this problem.  For one thing, one would get
high information OUTSIDE the sites.  Some people have published graphs like
this.
<p>

A nice way to display binding site data so you can see them and grasp their
meaning rapidly is by the sequence logo method.
The sequence logo for the example above is at
<a href = "http://www.lecb.ncifcrf.gov/~toms/gallery/hawaii.fig1.gif">
http://www.lecb.ncifcrf.gov/~toms/gallery/hawaii.fig1.gif</a>.
More information on sequence logos is
in the section
<a href="#Sequence.Logos">What are Sequence Logos?</a>

<p>
More information about the theory of BEFORE and AFTER states is given in the
papers
<a href="http://www.lecb.ncifcrf.gov/~toms/paper/nano2">
http://www.lecb.ncifcrf.gov/~toms/paper/nano2 
</a>,
<a href="http://www.lecb.ncifcrf.gov/~toms/paper/ccmm">
http://www.lecb.ncifcrf.gov/~toms/paper/ccmm</a>
and
<a href="http://www.lecb.ncifcrf.gov/~toms/paper/edmm">
http://www.lecb.ncifcrf.gov/~toms/paper/edmm</a>.

<p>
<h3 align=center><a name="Learn.More.About">
<hr>
<p>
How Can I Learn More About Information Theory and Biology?  References
</a></h3>

<p>
<h3 align=center><a name="REFERENCES-General">
REFERENCES - General</a>
</h3>

<p>
There are a huge number of papers related to this topic, just about
everything in molecular biology, lots of chemistry, physics, electronics,
evolutionary theory, thermodynamics, statistical mechanics and the kitchen
sink ...
References are given in BiBTeX
format, the bibliography program associated with LaTeX, the powerful and
portable typesetting program.

<p>
By arrangement, books that have prices listed can be ordered over Internet
from:

<p>
  Reiter's Scientific & Professional Books<br>
  2021 K Street, NW<br>
  Washington, DC  20006<br>
  1-800-537-4314<br>
  1-202-223-3327<br>
  1-202-296-9103 FAX<br>
  
 EMAIL:<br>
  <a href="mailto:books@reiters.com">books@reiters.com</a>
  <br>
  WWW:<br>
  <a href="http://reiters.com/">
  http://reiters.com/</a><br>

<p>
Shipping and handling charges are:  in the DC metropolitan area $4.00 for one
item, $0.50 for each additional item, outside the area $4.50 for one item,
$0.50 for each additional item.

<p>
The prices are current as of October 1994; because publishers are constantly
changing their prices, they should be considered estimates rather than
guaranteed prices.  To open an account you must first either phone or FAX
them and provide a credit card number.  Book orders can be then placed at any
time over the Internet.  **DO NOT SEND CREDIT CARD NUMBERS OVER THE
INTERNET!**

<p>
Reiter's carries all of the books on this list except "Information Theory:
Saving Bits", and that one can be special ordered.  If enough interest in
this book is generated by the FAQ, it will be added as regular stock.  (It
can also be ordered directly from the company using the information given.)

<p>
<h4>
Gonick's Wonderful books (Don't be shy!  They are worth the money!!):
<p>
</h4>

@book{Gonick.computers,<br>
author = "L. Gonick",<br>
title = "The Cartoon Guide to Computers",<br>
edition = "second",<br>
publisher = "HarperCollins",<br>
address = "New York, NY",<br>
isbn = "0-06-273097-5",<br>
price = "price as of 1994 October 31: \$11.00",<br>
year = "1991"}<br>
<p>

@book{Gonick.genetics,<br>
author = "L. Gonick",<br>
title = "The Cartoon Guide to Genetics",<br>
edition = "updated",<br>
publisher = "Barnes \& Nobel",<br>
address = "New York, NY",<br>
isbn = "0-06-273099-1",<br>
price = "price as of 1994 October 31: \$12.00",<br>
year = "1991"}<br>
<p>

@book{Gonick.physics,<br>
author = "L. Gonick<br>
 and A. Huffman",<br>
title = "The Cartoon Guide to Physics",<br>
publisher = "HarperPerennial",<br>
address = "New York, NY",<br>
isbn = "0-06-273100-9",<br>
price = "price as of 1994 October 31: \$12.00",<br>
year = "1990"}<br>
<p>

<h4>
 A good starting point if you don't know much molecular biology:
 (Two volumes)
</h4>
<p>

@book{Watson1987,<br>
author = "J. D. Watson<br>
 and N. H. Hopkins<br>
 and J. W. Roberts<br>
 and J. A. Steitz<br>
 and A. M. Weiner",<br>
title = "Molecular Biology of the Gene",<br>
edition = "fourth",<br>
publisher = "The Benjamin/Cummings Publishing Co., Inc.",<br>
address = "Menlo Park, California",<br>
isbn = "0-8053-9614-4",<br>
price = "price as of 1994 October 31: \$59.95",<br>
year = "1987"}<br>
<p>

<h4>
This book describes LaTex and BiBTeX:
</h4>
<p>

@book{Lamport1994,<br>
author = "L. Lamport",<br>
title = "\LaTeX: A Document Preparation System,<br>
User's Guide \& Reference Manual",<br>
edition = "second",<br>
publisher = "Addison-Wesley Publishing Company",<br>
address = "Reading, Massachusetts",<br>
isbn = "0-201-52983-1",<br>
price = "price as of 1994 October 31: \$32.95",<br>
year = "1994"}<br>

<p>
<h3 align=center><a name="REFERENCES-Information_Theory">
<hr>
<p>
REFERENCES - Information Theory
</a></h3>

<UL>

<LI>
<b>Basic References</b>

<UL>

  <LI>
John Pierce was at Bell Labs while Shannon
dreamed up information theory.  He saw the development
from the inside, and wrote it up in
"An Introduction to Information Theory:
Symbols, Signals and Noise".
Although it is not highly mathematical,
this book is still
the best one to start with because it gives
one a feeling for the scope and implications
of the theory, without dumping on the math,
yet without leaving out important topics that
later generations of popular writers skipped.

<p>
@book{Pierce1980,<br>
author = "J. R. Pierce",<br>
title = "An Introduction to Information Theory:<br>
Symbols, Signals and Noise",<br>
edition = "second",<br>
publisher = "Dover Publications, Inc.",<br>
address = "New York",<br>
isbn = "0-486-24061-4",<br>
comment = "<br>
original copyright 1961<br>
Ordering information:  Pierce1980 is currently available by mail from:<br>
   Dover Publications, Inc.<br>
   31 East 2nd street<br>
   Mineola, New York 11501<br>
order:<br>
   Pierce, An Introduction to Information Theory: Symbols, Signals and Noise<br>
   code number: 24061-4<br>
$7.95 + charges.  Payment in full, no telephone or credit card orders.<br>
Postage and Handling charges are:<br>
Bookrate: $3 (US only)<br>
UPS: $4.50 (US only, not Alaska or Hawaii or PO boxes)<br>
Foreign orders: add 20% of total (minimum $2.50)<br>
Sales Tax (Ny residents only)<br>
Foreign Orders Note: Remittances must be sent by international money order or
in U.S. funds via Federal Wire System to Chemical Bank, N. Y.  ABA
#021000128.  Mark all remittances `For the account of Dover Publications,
Inc.  #001 053 272'.  This information is from the Dover Math and Science
Catalogue 9/92", price = "price as of 1994 October 31: \$8.95", year =
"1980"}<br>

<p>
  <LI>
Christopher Hillman (hillman@math.washington.edu) suggests that Cover and
Thomas' book is a better starting point, but that's because he is a
mathematician.  People who have seen both could post their opinions.

<p>
@book{Cover.Thomas1991,<br>
author = "Thomas M. Cover<br>
 and Joy A. Thomas",<br>
title = "Elements of Information Theory",<br>
publisher = "John Wiley \& Sons, Inc.",<br>
address = "N. Y.",<br>
isbn = "0-471-06259-6", <br>
year = "1991"}

<p>
  <LI>
A good introduction to the mathematics, written for high school students:

<p>
@book{Sacco1988,<br>
author = "W. Sacco<br>
 and W. Copes<br>
 and C. Sloyer<br>
 and R. Stark",<br>
title = "Information Theory: Saving Bits",<br>
publisher = "Janson Publications, Inc.",<br>
comment = "original address was Providence, Rhode Island",<br>
address = "Dedham, MA",<br>
isbn = "0-939765-25-X",<br>
phone = "(800) 322-6284",<br>
price = "price as of 1994 October 31: \$11.95",<br>
year = "1988"}<br>

  </UL>

<p>
<LI>
<b>Important originals:</b>

  <UL>

<a name = "ShannonBib">
<p>
  <LI>
@article{Shannon1948,<br>
author = "C. E. Shannon",<br>
title = "A Mathematical Theory of Communication",<br>
year = "1948",<br>
journal = "Bell System Tech. J.",<br>
volume = "27",<br>
pages = "379-423, 623-656"}<br>
<a href =
"http://cm.bell-labs.com/cm/ms/what/shannonday/paper.html"
>On line version at Bell Labs</a>

<p>
  <LI>
@book{ShannonWeaver1949,<br>
author = "C. E. Shannon<br>
 and W. Weaver",<br>
title = "The Mathematical Theory of Communication",<br>
publisher = "University of Illinois Press",<br>
address = "Urbana",<br>
isbn = "0-252-72548-4",<br>
price = "price as of 1994 October 31: \$9.95",<br>
year = "1949"}<br>

<p>
  <LI>
@article{Shannon1949,<br>
author = "C. E. Shannon",<br>
title = "Communication in the Presence of Noise",<br>
year = "1949",<br>
journal = "Proc. IRE",<br>
volume = "37",<br>
pages = "10-21"}<br>

<p>
  <LI>
For the committed: The Complete Works!
<p>
@book{Sloane.Wyner1993,<br>
author = "N. J. A. Sloane and A. D. Wyner",<br>
title = "Claude Elwood Shannon: Collected Papers",<br>
publisher = "IEEE Press",<br>
address = "Piscataway, NJ",<br>
isbn = "0-7803-0434-9",<br>
comment = "IEEE Order Number: PC0331-9<br>ll
  To order directly by charge card (eg Visa works) you can call
  (908)-981-0060<br>
  $69.95 + $5 handling charge<br>
  delivery in about 2 weeks",<br>
price = "price as of 1994 October 31: \$69.95",<br>
comment = "this was previously called Shannon1993", <br>
year = "1993"}<br>

  </UL>

<p>
<LI>
<b>Other basic references</b>

  <UL>
<p>
  <LI>
How locks work and other cool stuff:

<p>
@book{Macaulay1988,<br>
author = "D. Macaulay",<br>
title = "The Way Things Work",<br>
publisher = "Houghton Mifflin Company",<br>
address = "Boston",<br>
isbn = "0-395-42857-2",<br>
price = "price as of 1994 October 31: \$29.95",<br>
comment = "This book is also available on Windows-Compatible CD-ROM<br>
  cdrom isbn = 1-56458-901-3  Price as of 1994 October 31: \$99.95",<br>
year = "1988"}<br>

<p>
  <LI>
Leff1990 gives a review of the Maxwell's Demon problem.<br>
See also
<a href="http://www.lecb.ncifcrf.gov/~toms/paper/edmm">
Schneider.edmm</a>,
listed below.
<p>
@book{Leff1990,<br>
author = "H. S. Leff and A. F. Rex",<br>
title = "Maxwell's Demon: Entropy, Information, Computing",<br>
publisher = "Princeton University Press",<br>
address = "Princeton, N. J.",<br>
phone = "1(800) 777-4726",<br>
isbn.hard = "0-691-08726-1 (hard cover)",<br>
price.hard = "price as of 1994 October 31: \$80.00",<br>
isbn.paper = "0-691-08727-X (paperback)",<br>
price.paper = "price as of 1994 October 31: \$26.95",<br>
year = "1990"}<br>

  </UL>

</UL>

<p>
<h3 align=center><a name="REFERENCES-Jaynes">
<hr>
<p>
REFERENCES - Jaynes
</a></h3>
<p>


@article{JaynesI,<br>
  author = "Edwin T. Jaynes",<br>
  title = "Information Theory and Statistical Mechanics",<br>
  year = 1957,<br>
  journal = "Physical Review",<br>
  volume = "106",<br>
  pages = "620-630"}<br>

<p>
@article{JaynesII,<br>
  author = "Edwin T. Jaynes",<br>
  title = "Information Theory and Statistical Mechanics. {II}",<br>
  year = 1957,<br>
  journal = "Physical Review",<br>
  volume = "108",<br>
  pages = "171-190"}<br>
  

<p>

A version of Jaynes' new book "PROBABILITY THEORY -- THE LOGIC OF SCIENCE"
is available on the net.  See:
<p>

<a href="ftp://bayes.wustl.edu/Jaynes.book/">
ftp://bayes.wustl.edu/Jaynes.book/</a><br>
Larry Bretthorst (<a
href="mailto:larry@bayes.wustl.edu">larry@bayes.wustl.edu</a>)

<p>
<a href="http://omega.albany.edu:8008/JaynesBook.html">
http://omega.albany.edu:8008/JaynesBook.html</a><br>
Carlos Rodriguez
(<a href="mailto:carlos@math.albany.edu">carlos@math.albany.edu</a>)
<p>

Tom Schneider's pointers to these places:<br>
<a href="http://www.lecb.ncifcrf.gov/~toms/jaynes.html">
http://www.lecb.ncifcrf.gov/~toms/jaynes.html</a>
<p>

Note:  The book is being written now and new versions come out every once
in a while.  One of these locations may be more up to date than the other.

<p>
<h3 align=center><a name="REFERENCES-Schneider">
<hr>
<p>
REFERENCES - Schneider
</a></h3>
<p>

To see online papers, go to 
<a href = "http://www.lecb.ncifcrf.gov/~toms/paper">
http://www.lecb.ncifcrf.gov/~toms/paper</a>.


<p>

@article{Schneider1986,<br>
author = "T. D. Schneider<br>
 and G. D. Stormo<br>
 and L. Gold<br>
 and A. Ehrenfeucht",<br>
title = "Information content of binding sites on nucleotide sequences",<br>
journal = "J. Mol. Biol.",<br>
volume = "188",<br>
pages = "415-431",<br>
year = "1986"}<br>

<p>

@inproceedings{Schneider1988,<br>
author = "T. D. Schneider",<br>
editor = "G. J. Erickson and C. R. Smith",<br>
title = "Information and entropy of patterns in genetic switches",<br>
booktitle = "Maximum-Entropy and Bayesian Methods in Science
and Engineering",<br>
volume = "2",<br>
pages = "147-154",<br>
publisher = "Kluwer Academic Publishers",<br>
address = "Dordrecht, The Netherlands",<br>
year = "1988"}<br>

<p>

@article{Schneider1989,<br>
author = "T. D. Schneider<br>
 and G. D. Stormo",<br>
title = "Excess Information at Bacteriophage {T7} Genomic Promoters<br>
Detected by a Random Cloning Technique",<br>
year = "1989",<br>
journal = "Nucl. Acids Res.",<br>
volume = "17",<br>
pages = "659-674"}<br>

<p>

@article{Schneider.Stephens.Logo,<br>
author = "T. D. Schneider<br>
 and R. M. Stephens",<br>
title = "Sequence Logos: A New Way to Display Consensus Sequences",<br>
journal = "Nucl. Acids Res.",<br>
volume = "18",<br>
pages = "6097-6100",<br>
year = "1990"}<br>

<p>

@article{Schneider.ccmm,<br>
author = "T. D. Schneider",<br>
title = "Theory of Molecular Machines.<br>
{I. Channel} Capacity of Molecular Machines",<br>
journal = "J. Theor. Biol.",<br>
volume = "148",<br>
number = "1",<br>
pages = "83-123",<br>
note = "{(Note: The figures were printed out of order!<br>
Fig. 1 is on p. 97.)}",<br>
year = 1991}<br>

<p>

@article{Schneider.edmm,<br>
author = "T. D. Schneider",<br>
title = "Theory of Molecular Machines.<br>
{II. Energy} Dissipation from Molecular Machines",<br>
journal = "J. Theor. Biol.",<br>
volume = "148",<br>
number = "1",<br>
pages = "125-137",<br>
year = 1991}<br>

<p>

@article{Herman.Schneider1992,<br>
author = "N. D. Herman<br>
  and T. D. Schneider",<br>
title = "High Information Conservation Implies that at Least Three Proteins
Bind Independently to {F} Plasmid {{\em incD\/}} Repeats",<br>
journal = "J. Bact.",<br>
volume = "174",<br>
pages = "3558-3560",<br>
year = "1992"}<br>

<p>

@article{Stephens.Schneider.Splice,<br>
author = "R. M. Stephens<br>
  and T. D. Schneider",<br>
title = "Features of spliceosome evolution and function<br>
inferred from an analysis of the information at human splice sites",<br>
journal = "J. Mol. Biol.",<br>
volume = "228",<br>
pages = "1124-1136",<br>
year = "1992"}<br>

<p>

@article{Papp.helixrepa,<br>
author = "P. P. Papp<br>
 and D. K. Chattoraj<br>
 and T. D. Schneider",<br>
title = "Information Analysis of Sequences that Bind
the Replication Initiator {RepA}",<br>
journal = "J. Mol. Biol.",<br>
comment = "Cover of 233, number 2!",<br>
volume = "233",<br>
pages = "219-230",<br>
year = "1993"}<br>

<p>

@article{Schneider.nano2,<br>
author = "T. D. Schneider",<br>
title = "Sequence Logos, Machine/Channel Capacity,<br>
{Maxwell}'s Demon, and Molecular Computers:
a Review of the Theory of Molecular Machines",<br>
journal = "Nanotechnology",<br>
volume = "5",<br>
number = "1",<br>
pages = "1-18",<br>
year = "1994"}<br>
ftp://ftp.ncifcrf.gov/pub/delila/nano2.ps<br>

<p>
<h3 align=center><a name="REFERENCES-Yockey">
<hr>
<p>
REFERENCES - Yockey
</a></h3>
<p>



@book{Yockey1958a,<br>
editor = "Hubert P. Yockey and Robert P. Platzman and Henry Quastler",<br>
title = "Symposium on Information Theory in Biology",<br>
booktitle = "Symposium on Information Theory in Biology",<br>
publisher = "Pergamon Press",<br>
address = "New York, London",<br>
comment = "out of print",<br>
year = "1958"}<br>

<p>

@article{Yockey1981,<br>
author = "Hubert P. Yockey",<br>
year = 1981,<br>
title = "Self-organization Origin of Life Scenarios and Information Theory",<br>
journal = "J. Theor. Biol.",<br>
volume = "91",<br>
pages = "13-31"}<br>

<p>

@book{Yockey1992,<br>
author = "H. P. Yockey",<br>
title = "Information Theory in Molecular Biology",<br>
publisher = "Cambridge University Press",<br>
address = "Cambridge",<br>
isbn = "0-521-35005-0",<br>
comment = "40 West 20th Street,<br>
New York, N. Y.  10011-4211,<br>
order number 350050",<br>
phone = "1-800-827-7423",<br>
price = "price as of 1994 October 31: \$74.95",<br>
year = "1992"}<br>

<p>

Following is Hubert Yockey's reference list:
<p>

<ul>
<li>Yockey, Hubert P. Information Theory and Molecular Biology, Cambridge UK:
Cambridge University Press (1992)
<p>

<li>When is random random? Nature 344 (1990) p823, Hubert P. Yockey
<p>

<li>Yockey, Hubert P. (1981). Self-organization origin of life scenarios and
information theory. Journal of Theoretical Biology, 91, 13-31.
<p>

<li>Yockey, Hubert P. (1979). Do overlapping genes violate molecular biology and
the theory of evolution? Journal of Theoretical Biology, 80, 21-26.
<p>

<li>Yockey, Hubert P. (1978). Can the Central Dogma be derived from information
theory? Journal of Theoretical Biology, 74, 149-152.
<p>

<li>Yockey, Hubert P. (1977a). A prescription which predicts functionally
equivalent residues at given sites in protein sequences. 67, 337-343.
<p>

<li>Yockey, Hubert P. (1977b). On the information content of cytochrome c.
Journal of Theoretical Biology, 67, 345-376.
<p>

<li>Yockey, Hubert P. (1977c). A calculation of the probability of spontaneous
biogenesis by information theory. Journal of Theoretical Biology, 67,
377-398.
<p>

<li>Yockey, Hubert P (1974). An application of information theory to the Central
Dogma and the sequence hypothesis. Journal of Theoretical Biology,.46,
369-406.
<p>

<li>Yockey, Hubert P. (1960) The Use of Information Theory in Aging and
Radiation Damage In The Biology of Aging American Institute of Biological
Sciences Symposium No. 6 (160) pp338-347.
<p>

<li>Yockey, Hubert P., Platzman, Robert P. & Quastler, Henry, eds. (1958a).
Symposium on Information Theory in Biology, New York, London: Pergamon Press.
<p>

<li>Yockey, Hubert P. (1958b). A study of aging, thermal killing and radiation
damage by information theory. In Symposium on Information Theory in Biology.
eds. Hubert P. Yockey, Robert Platzman & Henry Quastler, pp297-316. New
York,London: Pergamon Press.
<p>

<li>Yockey, Hubert P. (1956). An application of information theory to the
physics of tissue damage. Radiation.Research, 5, 146-155.
<p>

<li>Information in bits and bytes; Reply to Lifson's Review of
"Information Theory and Molecular" Biology BioEssays v17 p85-88 (1995)
<p>

<li>Comments on "Let there be life; Thermodynamic Reflections on
Biogenesis and Evolution by Avshalom C. Elitzur  Journal of Theoretical
Biology in press (1995).
<p>
</ul>

<p>
<h3 align=center><a name="REFERENCES-Adleman">
<hr>
<p>
REFERENCES - Adleman and papers related to molecular computation
</a></h3>
<p>

Tom Schneider has a list of
<a href = "http://www.lecb.ncifcrf.gov/~toms/molecularcomputation.html">
molecular computation resources</a>.

<p>
A longer and more complete list of references is
maintained by J.H.M.Dassen (jdassen@wi.leidenuniv.nl)
in
<a href = "http://www.wi.LeidenUniv.nl/~jdassen/dna.bib">
A biblography on Molecular Computation and Splicing Systems
(http://www.wi.LeidenUniv.nl/~jdassen/dna.bib)</a>.
There are also
<a href = "http://www.wi.LeidenUniv.nl/~jdassen/dna.html">
hyperlinks to most of the (90+) papers
(http://www.wi.LeidenUniv.nl/~jdassen/dna.html)</a>.

<p>
@article{Adleman1994,<br>
author = "Leonard M. Adleman",<br>
title = "Molecular computation of solutions to combinatorial problems",<br>
journal = "Science",<br>
volume = "266",<br>
pages = "1021-1024",<br>
date = "November 11",<br>
year = 1994}<br>

<p>

@article{Baum1995,<br>
author = "Eric B. Baum",<br>
title = "Building an associative memory vastly larger that the brain",<br>
journal = "Science",<br>
volume = "268",<br>
pages = "583-585",<br>
date = "April 28",<br>
year = 1995}<br>

<p>

@article{Lipton1995,<br>
author = "Richard J. Lipton",<br>
title = "DNA solution of hard computational problems",<br>
journal = "Science",<br>
volume = "268",<br>
pages = "542-545",<br>
date = "April 28",<br>
year = 1995}<br>

<p>

@manuscript{Adleman1995,<br>
author = "Leonard M. Adleman",<br>
title = "On constructing a molecular computer",<br>
note = "Available by anonymous ftp:<br>
/pub/csinfo/papers/adleman/molecular_computer.ps on usc.edu",<br>
year = 1995}<br>

<p>

Other available manuscripts:
<p>

1. Dick Lipton of Princeton<br>
Speeding up computations via molecular biology. Draft.  Dec. 9, 1994.<br>
<a href="ftp://ftp.cs.princeton.edu/pub/people/rjl/bio.ps">
 ftp://ftp.cs.princeton.edu/pub/people/rjl/bio.ps</a>
<p>

2. Dan Boneh of Princeton has several manuscripts available at:<br>
Breaking DES Using a Molecular Computer.<br>
Authors: D. Boneh, C. Dunworth, R. Lipton<br>
This paper contains the talk from the workshop.<br>
<a href="http://www.cs.princeton.edu/~dabo/biocomp.html">
http://www.cs.princeton.edu/~dabo/biocomp.html</a>
<p>

On the Computational Power of DNA.<br>
Authors: D. Boneh, C. Dunworth, R. Lipton, J. Sgall<br>
This is a new paper which contains several results:<br>
a. Shows how to solve the circuit satisfaction problem.<br>
b. Shows how to solve optimization problems such as MAX-Clique without going
   through decision problems.<br>
c. Shows how to evaluate predicates in the polynomial hirarchy.<br>
<p>

Making DNA Computers Error Resistant.<br>
Authors: D. Boneh, R. Lipton<br>
This paper shows how to transform volume reducing DNA algorithms into
algorithm that are resistant to errors.

<p>
<h3 align=center><a name="REFERENCES-Yagil">
<hr>
<p>
REFERENCES - Gad Yagil and papers related to Algorithmic Information
   Theory (AIT) or Algorithmic Complexity
</a></h3>
<p>

An alternative way to analyze biosystems is by the Algorithmic Information
Theory (AIT) or Algorithmic Complexity (AC) approach, first formulated by
Kolmogoroff, Solomonoff and Chaitin in the 1960's.  According to this
approach, the information in a string of symbols is equal to the length of
the shortest program caparisons of reproducing the string.  This concept has
been reformulated to tackle real molecular and biosystems ("Structural
Complexity") and applied to a range of biosystems by G. Yagil. The more
recent publications, which include references to the work of Kolmogoroff and
of Chaitin, can be found at:
</p>

<p>
<a href =
"http://www.weizmann.ac.il/~lcyagil">http://www.weizmann.ac.il/~lcyagil</a>
<br> also at <a href = "http://interjournal.org">http://interjournal.org</a>,
Manuscript Number 135.  (Do a search for the manuscript number.)
</p>

<p>
The book of Cover and Thomas covers AC extensively.  In particular, it shows
that under certain conditions, AC can become equal to the Shannon information
(or uncertainty) measure.  In a series of papers, C.H. Bennett has proposed a
concept of "logical depth", related to the time required by a universal
machine to compute a sequence, as another measure of the information content
of a string or sequence:
</p>

see: C.H.  Bennett, "Logical Depth and Physical Complexity".
In: "The Universal Turing Machine -A half century", Rolf Herken, Editor,
Oxford University press, 1988.
</p>

Gad Yagil, Ph. D. <br>
Dept. of Molecular Cell Biology <br>
The Weizmann Institute of Science <br>
Rehovot, Israel, 76100 <br>
Tel. 089-460-918 (home) <br>
Fax  089-344-125 <br>
e-mail <a
href="mailto:lcyagil@wiccmail.weizmann.ac.il">lcyagil@wiccmail.weizmann.ac.il</a>.

<p>
<h3 align=center><a name="REFERENCES-entropy-www">
<hr>
<p>
REFERENCES - Entropy on the World Wide Web.
<! --Chris Hillman and papers related to entropy -->
</a></h3>
<p>

<ul>

<li>
Entropy on the World Wide Web.
Chris no longer maintains the page, it is maintained by
Roland Gunesch (Mathematics, Penn State).
<!--
<a href = "http://www.math.washington.edu/~hillman/entropy.html">
http://www.math.washington.edu/~hillman/entropy.html</a>
-->
<a href =
"http://www.math.psu.edu/gunesch/entropy.html"
>
http://www.math.psu.edu/gunesch/entropy.html</a>

<li> Chris Hillman's Home Page: 
<a href = "http://www.math.washington.edu/~hillman/personal.html">
http://www.math.washington.edu/~hillman/personal.html</a>

</ul>

<p>
<h3 align=center><a name="Send.Me.Papers">
<hr>
<p>
Will Authors Send Me Papers?
</a></h3>

<p>
Tom Schneider will mail you copies of some of his papers.
You can request them through the World Wide Web from
<a href="http://www.lecb.ncifcrf.gov/~toms/papers.html">
http://www.lecb.ncifcrf.gov/~toms/papers.html</a>
or by sending
your physical address to him at
<a href="mailto:toms@ncifcrf.gov">toms@ncifcrf.gov</a>.

<p>
If you are willing to send out papers or have papers you would like listed
here, please contact
<a href="mailto:toms@ncifcrf.gov">Tom Schneider</a>.

<p>
<h3 align=center><a name="BIG.Coins">
<hr>
<p>
<IMG SRC ="http://www.lecb.ncifcrf.gov/~toms/icons/head.gif" align = left
ALT = "coin: head">
<IMG SRC ="http://www.lecb.ncifcrf.gov/~toms/icons/tail.gif" align = right
ALT = "coin: tail">
Where Can I Get BIG Coins?
</a></h3>

BIG coins are nice for explaining that a bit represents the choice between
two equally likely possibilities.
<br clear = all>

<p>
News Emporium, Inc. (703) 661-3550 sells
large coins at Dulles International Airport.

<p>
<a href="http://www.parksandhistory.org/">Parks and History</a>
has big coins for sale.  They will have a web site Bookshop soon.
In the meantime, you could call
(202) 755-0461 or (800) 990-7275.  They accept VISA, MasterCard
or American Express.
Contact:
<a href="mailto:LDepew@parksandhistory.org"> Linda Depew</a>
their Mail Order & Wholesale Manager.

<p>
If you find other sources, please tell
<a href="mailto:toms@ncifcrf.gov">Tom Schneider</a>.
<br clear = all>


<p>
<h3 align=center><a name="Sequence.Logos">
<hr>
<p>
What are Sequence Logos?
</a></h3>

<IMG SRC ="http://www.lecb.ncifcrf.gov/~toms/icons/donor.small.gif"
align = left
Alt = "human splice donor sites sequence logo">
A sequence logo is a graphical method for showing patterns
created by using information theory.
<br clear = all>

<p>
<h3 align=center><a name="Sequence.Logos.on.the.Web">
<hr>
<p>
How Do I find Sequence Logos on the Web?
</a></h3>
<p>
<a href="http://www.lecb.ncifcrf.gov/~toms/sequencelogo.html">
http://www.lecb.ncifcrf.gov/~toms/sequencelogo.html</a>

<p>
<h3 align=center><a name="Shell.Script.for.Making.Sequence.Logos">
<hr>
<p>
Is There a Shell Script for Making Sequence Logos?
<p>
</a></h3>
<p>

Yes, you will find the one Shmuel Pietrokovski wrote in the ftp archive
<a href="ftp://ftp.ncifcrf.gov/pub/delila/logoaid">ftp.ncifcrf.gov in
pub/delila/logoaid</a>.

(Also available in
<a href="ftp://bioinformatics.weizmann.ac.il/pub/software/logoaid">
bioinformatics.weizmann.ac.il/pub/software/logoaid</a>.)

<p>
<h3 align=center><a name="Web.Page for.Making.Sequence.Logos">
<hr>
<p>
Is There a World Wide Web Page for Making Sequence Logos?
</a></h3>
<p>

Yes, Steve Brenner has done it!
<p>
<a href="http://www.bio.cam.ac.uk/seqlogo/">
http://www.bio.cam.ac.uk/seqlogo/</a>

<p>
<h3 align=center><a name="other.orgs">
<hr>
<p>
Are There Other Organizations for Information Theory?
</a></h3>
<p>

<a href = "http://it.ucsd.edu/">IEEE Information Theory Society</a>

<p>
<h3 align=center><a name="Acknowledgments">
<hr>
<p>
Acknowledgments
</a></h3>
<p>

This FAQ is written and maintained by Tom Schneider.
It was HTMLized by Susan Hogarth
(sjhogart@unity.ncsu.edu)</a> in February,
1997 but is NOT maintained by her.
Please look at <a href="#Who.Takes.Care.of.This.Group">Who Takes Care of This
Group</a> if you have questions about this FAQ.

<p>
<hr>


<! The following blanks extend the bottom of the faq
so that jumps to the last few sections work properly>
<br> <br> <br> <br> <br> <br> <br> <br> <br> <br>
<br> <br> <br> <br> <br> <br> <br> <br> <br> <br>
<br> <br> <br> <br> <br> <br> <br> <br> <br> <br>
<br> <br> <br> <br> <br> <br> <br> <br> <br> <br>

</body>
</html>

