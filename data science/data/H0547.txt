ID=H0547
URL=http://www.klab.caltech.edu/vision.html
SIZE=10313
DATE=11/07/2002
TIME=17:06:05
DATASET=Biology
HTML=<html>
<head>
<title>Vision research</title>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
</head>

<body bgcolor="#FFFFCC">
<div align="center"> 
  <p><!-- Fireworks 3.0  Dreamweaver 3.0 LBI target.  Created Fri Feb 11 18:53:02 GMT-0800 2000 --> 
    <img name="vision" src="Images/vision.gif" width="600" height="137" border="0" usemap="#m_vision"><map name="m_vision"> 
      <area shape="rect" coords="288,52,396,86" href="index.html" > <area shape="rect" coords="484,24,563,103" href="http://www.caltech.edu" > 
    </map> <!-- Fireworks 3.0  Dreamweaver 3.0 LBI target.  Created Fri Feb 11 18:27:30 GMT-0800 2000 --> 
    <map name="m_vision"> <area shape="rect" coords="288,52,396,86" href="index.html" > 
      <area shape="rect" coords="484,24,563,103" href="http://www.caltech.edu" > 
    </map> </p>
</div>
  
<table width="560" border="0" cellspacing="0" cellpadding="0" align="center">
  <tr> 
      
    <td> <font face="Times New Roman, Times, serif"> 
      <p align="left"> We are interested in understanding the mechanisms underlying 
        the <b>primate visual system</b>--a system to which nearly half of our 
        cerebral cortex is devoted. The massive complexity of this system is belied 
        by the apparent ease with which we can: 
      <ul>
        <li> recognize the face of a friend 
        <li> drive at high speeds on a crowded highway 
        <li> visualize the particular shade of blue in our carpet as we look for 
          a matching color of paint in the store 
        <li> identify someone's handwriting 
        <li> track an oncoming baseball 
      </ul>
      There are many appraches, both experimental and theoretical, that are currently 
      used to study the visual system; most of these approaches are used in our 
      lab or in our collaborators' labs. Together, the various approaches outline 
      the steps of the scientific method-- 1) psychophysics and neuropsychology 
      suggest constraints on the behavior of a visual subsystem, 2) electrophysiology 
      and functional brain imaging give constraints on the architecture of the 
      subsystem, 3) together these suggest a particular computer model, and finally 
      4) issues confronted during the implementation of the computer model may 
      suggest new directions for experimental research. Following is a brief description 
      of each of these techniques, along with a summary of ongoing work in each 
      area. 
      <p> <A HREF="Images/random_dot.mpeg"><IMG
		    SRC="Images/random_dot.gif" ALIGN="RIGHT" width="40" height="40" border="0"></A> 
        <STRONG>Psychophysics</STRONG>. Psychophysics uses very detailed measurements 
        about people's ability to perform a visual task in order to infer something 
        about the brain mechanism responsible for that task. This often involves 
        measuring a threshold--for example, what is the smallest detectable change 
        in brightness of a light source? By identifying the limits of a system, 
        one learns more about how the system operates in normal ranges. A main 
        focus of our psychophysical investigations is selective visual (focal) 
        attention in normal subjects, using techniques from sensory psychology, 
        in particular the <I>dual-task </I> paradigm (Dr. Achim Braun, <A HREF= "/~geraint">Dr. 
        Geraint Rees</A>, &amp; <A HREF= "/~barbara/">Dr. Barbara Zenger</A>). 
        In addition, <A HREF= "/~rjpeters">Rob Peters</A> is starting a project 
        on visual object recognition in humans, carried out in tandem with <A
		    HREF="http://www.klab.caltech.edu/%7Egabbiani/">Dr. Fabrizio Gabbiani</A> 
        and Prof. Nikos Logothetis who are investigating the exact same object 
        recognition paradigm in monkeys. 
      <p> <STRONG>Electrophysiology</STRONG>. This technique involves making electrical 
        recordings from individual neurons by inserting a metal or glass electrode 
        directly into the brain. For obvious reasons, this technique cannot typically 
        be used with humans, so most electrophysiological data comes from monkeys. 
        However, some limited electrophysiological data are becoming available 
        from human patients with epilepsy, who often have electrodes temporarily 
        inserted into their brains as part of their medical treatment.<a
			 href = "http://www.cns.caltech.edu/%7Egabriel/">Gabriel Kreiman</a> 
        is collaborating with Dr. Itzhak Fried (UCLA) to use such human electrophysiological 
        data to study the roles of the temporal lobe and nearby subcortical structures 
        in object recognition. We have recorded from several multiple units in 
        the human medial temporal lobe. We characterized the visual responses 
        showing that single neurons respond selectively to complex stimuli including 
        faces, objects and spatial layouts. We also recorded the neuronal activity 
        while the subjects had to imagine the stimuli with the eyes closed. We 
        found that single neurons changed their activity selectively depending 
        on the stimuli they were recreating on their &quot;mind's eye&quot;. Furthermore, 
        most of these neurons had the same selectivity during imagery and vision. 
        See Kreiman, G., Koch, C. & Fried, I. Category-specific visual responses 
        of single neurons in the human medial temporal lobe. Nat. Neurosci. 3, 
        946-953 (2000). Kreiman, G., Koch, C. & Fried, I. Imagery neurons in the 
        human brain. Nature (In Press) 
      <p> <STRONG>Neuropsychology</STRONG>. This discipline attempts to make associations 
        between brain regions and specific functionality by studying the symptoms 
        of patients with damage to their visual system due to stroke or other 
        injury or disease. It is important to discover not only which visual abilities 
        are lost when a region is damaged, but also which abilities are retained. 
      <p> <IMG SRC="/~koch/images/christofS09-mri-small.gif"
		    ALIGN="RIGHT"> <STRONG>Functional brain imaging</STRONG>. The last 
        several years have seen an explosion of research in the area of functional 
        brain imaging, typically function magnetic resonance imaging (fMRI). This 
        technique has several advantages over electrophysiology: it is a non-invasive 
        procedure that can be done with normal human subjects, and it allows the 
        entire brain to be studied at once, rather than one neuron at a time. 
        However, it has its disadvantages as well: it has poor spatial and temporal 
        resolution compared to electrical recordings, and it does not directly 
        measure electrical activity in neurons, but rather a side effect (blood 
        oxygenation level). In collaboration with Linda Chang, M.D. and Thomas 
        Ernst, Ph.D. at UCLA-Harbor Medical Center, we are using fMRI to investigate 
        the neuronal basis of object recognition in human subjects (<A HREF= "/~jovicich">Dr. 
        Jorge Jovicich</A>, a joint post-doctoral fellow with Drs. Chang and Ernst; 
        <A HREF = "/~rjpeters">Rob Peters</A>). Dr. Geraint Rees continues to 
        use fMRI to investigate the neural bases of selective attention and visual 
        awareness in collaboration with the <a href="http://www.fil.ion.ucl.ac.uk">Functional 
        Imaging Laboratory</a> at <a href="http://www.ucl.ac.uk">University College 
        London</a>. 
      <p> <STRONG>Computational modeling.</STRONG> Understanding complex information-processing 
        tasks, such as the spatial perception, motion or selective, visual attention, 
        requires a firm grasp of how the problems can be solved at the computational 
        level, and how the resulting algorithms can be implemented onto the known 
        architecture of the striate and extrastriate cortical areas (as well as 
        associated subcortical areas) in the primate visual system. By tweaking 
        the parameters of computer models to compare their behavior with data 
        from psychophysics, electrophysiology, or functional brain imaging, we 
        gain an understanding of the important variables in biological vision. 
      <p> We use analytical methods, coupled with detailed neural network simulations 
        of the appropriate circuitry, to model many of those same visual subsystems 
        that we study with experimental approaches: motion perception, selective 
        visual (focal) attention (Dr. Steffen Egner, <A
		    HREF="/~itti/">Laurent Itti</A>, <A HREF=
		    "/~geraint">Dr. Geraint Rees</A>, <A HREF =
		    "/~barbara/">Dr. Barbara Zenger</A>, Dr. Jochen Braun), object recognition 
        (<A HREF="http://www.klab.caltech.edu/%7Egabbiani/">Dr. Fabrizio Gabbiani</A>, 
        <A HREF= "/~rjpeters">Rob Peters</A>). For a cool Java applet demo of 
        our saliency-based attention-system, click <A HREF="/~itti/attention/"> 
        here.</A> 
      <p><STRONG>Visual illusions</STRONG>. Our laboratory exploits visual illusions, 
        such as the <I>Breathing Square Illusion</I> <A HREF= "breathing_square.html">(Java 
        applet demo)</A>, as a window onto the algorithms and neural mechanisms 
        underlying visual perception in primates. <A HREF
		    = "http://neuro.caltech.edu/~seckel/"> Al Seckel</A> is editing and 
        researching an extensive collection of such illusions (many of them non-visual), 
        as well as illusory artforms and making them available to the general 
        community via a beautiful and highly interactive <A HREF =
		    "http://www.illusionworks.com/"> website</A>. </p>
      </font> </td>
    </tr>
  </table>
  <center>
    <hr width="560" noshade align="center" size="1">
  <font face="Arial, Helvetica, sans-serif" size="-1"><a href="index.html">[Home]</a> 
  <a href="news.html">[News]</a> <a href="research.html">[Research]</a> <a href="people.html">[People]</a> 
  <a href="papers.html">[Papers]</a> <a href="classes.html">[Classes]</a> <a href="jobs.html">[Jobs]</a></font>
</center>
</body>
</html>

