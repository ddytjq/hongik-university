ID=G0917
URL=http://www.astro.ucla.edu/~wright/statistics/
SIZE=6592
DATE=09/07/2002
TIME=16:21:38
DATASET=Astronomy
HTML=<HTML><HEAD><TITLE>Sex, Lies and Statistics</TITLE>
</HEAD><BODY BGCOLOR="#FFFFFF"><CENTER><HR>
<H1>Journal Club Talk on Statistics</H1><HR>
<H1>SEX, LIES &amp; STATISTICS</H1>
<BR><H2>by <A HREF="../intro.html">Ned Wright</A></H2>
</CENTER>



<P>There are 4 kinds of lies:
<OL>
<LI>Lies
<LI><A HREF="fn1.html">Damn Lies</A>
<LI>Statistics
<LI>Bayesian Statistics
</OL>
</P>

<P>Q: What is a statistic?<BR>
A: A function of one or more random variables.
</P>

<P>
Usually statistics are designed to extract useful information from a noisy
collection of data, such as using the median to find the central value
of a set of measurements.
</P>

<HR>

<IMG SRC="Thomas_Bayes.jpg" ALIGN=RIGHT WIDHT=268 HEIGHT=326>
<P>Q: Who was Bayes?</P>
<P>A: A: Thomas Bayes, 1702-1761, a Presbyterian minister.  
Bayes was elected
a Fellow of the Royal Society in 1742 despite the fact that at that time
he had no published works on mathematics, indeed none were published in
his lifetime under his own name.

Bayes set out his theory of probability in <EM>Essay towards solving a
problem in the doctrine of chances</EM> published in the Philosophical
Transactions of the Royal Society of London in 1764. The paper was sent
to the Royal Society by Richard Price, a friend of Bayes', who wrote:
<EM>
I now send you an essay which I have found among the papers of our
deceased friend Mr Bayes, and which, in my opinion, has great merit...</EM>
<BR CLEAR=RIGHT>
<HR>
<CENTER>
<H2>Bayes's Theorem</H2><BR>
<IMG SRC="bayes.gif" WIDTH=565 HEIGHT=565><BR>
Prob of A&amp;B = (Prob of A) times (Prob of B given A)<BR>
P(A&amp;B) = P(A)P(B|A) = P(B)P(B|A)<BR><HR>
<IMG SRC="statistics-4.gif" WIDTH=650 HEIGHT=466><BR><HR>
<IMG SRC="statistics-5.gif" WIDTH=650 HEIGHT=466><BR><HR>
<IMG SRC="statistics-6.gif" WIDTH=650 HEIGHT=466><BR><HR>
<IMG SRC="statistics-7.gif" WIDTH=650 HEIGHT=466><BR><HR>
</CENTER>
<P>
Thus the MLE (maximum likelihood estimator) for the centroid is the mean
when the data are Gaussian,
but the MLE for the standard
deviation is <EM>biased</EM> -- the prefactor should be 
<EM>(n-1)<SUP>-1</SUP></EM>.  But
for large data sets this error goes away, so the MLE's are said to be
<EM>asymptotically</EM> unbiased.
But if you divide your data into a large number of subsets, and get
MLE's for each subset, and then average the estimators, this bias can
get to be statistically significant.
</P>

<P>
MLE's are also <EM>efficient</EM>, so they are generally good things to
use.
</P>
<HR>
<CENTER>
<IMG SRC="statistics-9.gif" WIDTH=650 HEIGHT=466><BR><HR>
<IMG SRC="statistics-10.gif" WIDTH=650 HEIGHT=466><BR><HR>
<IMG SRC="statistics-11.gif" WIDTH=644 HEIGHT=336><BR><HR>
</CENTER><P>
This situation occurs in practice when data are digitized with a least
significant bit that is larger than the actual noise.  If you have data
taken under these circumstances, you should consider using <EM>minimax</EM>
fitting, where you minimize the maximum absolute value of the error
instead of minimizing the sum of the squares of the errors.
</P><HR><CENTER>
<IMG SRC="statistics-13.gif" WIDTH=650 HEIGHT=466><BR><HR>
<IMG SRC="statistics-14.gif" WIDTH=650 HEIGHT=466><BR><HR>
<IMG SRC="statistics-15.gif" WIDTH=650 HEIGHT=466><BR><HR>
<IMG SRC="statistics-16.gif" WIDTH=650 HEIGHT=466><BR><HR>
<H2>BACK TO BAYES</H2>
</CENTER>
<P>
If one does two independent experiments, then the combined likelihood of
the two experiments is<BR>
<EM>L(M) = L<SUB>1</SUB>(M) L<SUB>2</SUB>(M)</EM>
<BR>
because they are independent.
So if experiment 1 was done prior to our experiment, we could use
<EM>L<SUB>1</SUB>(M)</EM> as the prior distribution in Bayesian statistics.
</P>

<P>
However, it is a good idea to have separate discussions of what our
experiment says about the models, and what the combination of all
experiments say about the models.
Our experiment is well described by the likelihood function for our
data.
The combination of all experiments is well described by the product of
all their likelihood functions.
</P>

<P>
If these experiments are any good, then the combined likelihood will be
sharply peaked.  But if the experiments are not very definitive, then
<EM>a priori</EM> assumptions about the model can determine the most likely
case.  These assumptions can be codified in the prior distribution.
Since the Bayesian approach gives us a place to put our <EM>a priori</EM>
assumptions, it encourages us to think about them, which is generally
a good thing.
but if the choice of the prior distribution has a significant effect
on the outcome, then we just don't have enough data.
</P>
<HR>
<CENTER>
<IMG SRC="statistics-19.gif" WIDTH=650 HEIGHT=466><BR><HR>
<IMG SRC="statistics-20.gif" WIDTH=650 HEIGHT=466><BR><HR>
</CENTER><P>
Since I like to think that observations do matter, I take this with a
BIG grain of salt.
</P><HR><CENTER>
<IMG SRC="statistics-22.gif" WIDTH=650 HEIGHT=466><BR><HR>
<IMG SRC="statistics-23.gif" WIDTH=650 HEIGHT=466><BR><HR>
<IMG SRC="statistics-24.gif" WIDTH=650 HEIGHT=466><BR><HR>
<IMG SRC="statistics-25.gif" WIDTH=650 HEIGHT=466><BR><HR>
<IMG SRC="random_process.gif" WIDTH=436 HEIGHT-586><BR>
Three random processes with the same correlation function and hence
power spectrum, but very different two-point probability
densities.<BR><HR>
<IMG SRC="gaussian_not_stationary.gif" WIDTH=432 HEIGHT=351"><BR>
A random process which is Gaussian but not stationary: the standard
deviation varies with time.<BR><HR>
<IMG SRC="statistics-26.gif" WIDTH=650 HEIGHT=466><BR><HR>
<IMG SRC="gs_not_ergodic.gif" WIDTH=431 HEIGHT=570><BR>
Top: 3 realizations of
a random process which is Gaussian and stationary but not ergodic.<BR>
The two-point pdf from one realization sampled at many times is very
different from the two-point pdf from many realizations.<BR><HR>

<P><A HREF="../intro.html">Ned Wright's Home Page</A></P>

<P>
Cosmology <A HREF="../cosmology_faq.html">FAQ</A> |
<A HREF="../cosmolog.htm">Tutorial</A> :
<A HREF="../cosmo_01.htm"> Part 1 </A> |
<A HREF="../cosmo_02.htm"> Part 2 </A> |
<A HREF="../cosmo_03.htm"> Part 3 </A> |
<A HREF="../cosmo_04.htm"> Part 4 </A> |
<A HREF="../age.html"> Age </A> |
<A HREF="../distance.htm"> Distances </A> |
<A HREF="../cosmobib.html"> Bibliography </A> |
<A HREF="../relatvty.htm"> Relativity </A>
</P>
<HR>
&copy; 1997-1999 <A HREF="mailto:wright@astro.ucla.edu">Edward 
L. Wright</A> - Posted 
Wed Apr 14 12:23:03 PDT 1999
<HR></CENTER></BODY></HTML>

