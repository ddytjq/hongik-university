ID=H0820
URL=http://www.klab.caltech.edu/~itti/topdown/97_NIPS/node9.html
SIZE=8213
DATE=11/07/2002
TIME=17:08:19
DATASET=Biology
HTML=<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML 2.0//EN">
<!--Converted with LaTeX2HTML 96.1 (Feb 5, 1996) by Nikos Drakos (nikos@cbl.leeds.ac.uk), CBLU, University of Leeds -->
<HTML>
<HEAD>
<TITLE>DISCUSSION AND CONCLUSION</TITLE>
<META NAME="description" CONTENT="DISCUSSION AND CONCLUSION">
<META NAME="keywords" CONTENT="paper">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">
<LINK REL=STYLESHEET HREF="paper.css">
</HEAD>
<BODY BACKGROUND="bg.jpg" BGCOLOR="#F1EEFF" LANG="EN">
 <A NAME="tex2html106" HREF="node10.html"><IMG WIDTH=37 HEIGHT=24 ALIGN=BOTTOM ALT="next" SRC="next.gif"></A> <A NAME="tex2html104" HREF="paper.html"><IMG WIDTH=26 HEIGHT=24 ALIGN=BOTTOM ALT="up" SRC="up.gif"></A> <A NAME="tex2html98" HREF="node8.html"><IMG WIDTH=63 HEIGHT=24 ALIGN=BOTTOM ALT="previous" SRC="prev.gif"></A>   <BR>
<B> Next:</B> <A NAME="tex2html107" HREF="node10.html">References</A>
<B>Up:</B> <A NAME="tex2html105" HREF="paper.html">A Model of Early </A>
<B> Previous:</B> <A NAME="tex2html99" HREF="node8.html">Predictions</A>
<BR> <P>
<H1><A NAME="SECTION00040000000000000000">DISCUSSION AND CONCLUSION</A></H1>
<P>
We have developed a model of early visual processing in humans which
<IMG WIDTH=1 HEIGHT=25 ALIGN=MIDDLE SRC="spc.gif">
accounts for a wide range of measured spatial vision thresholds and
<IMG WIDTH=1 HEIGHT=25 ALIGN=MIDDLE SRC="spc.gif">
which predicts behavioral thresholds for a potentially unlimited
<IMG WIDTH=1 HEIGHT=25 ALIGN=MIDDLE SRC="spc.gif">
number of spatial discriminations.  In addition to orientation- and
<IMG WIDTH=1 HEIGHT=25 ALIGN=MIDDLE SRC="spc.gif">
spatial-frequency-tuned units, we have found it necessary to assume
<IMG WIDTH=1 HEIGHT=25 ALIGN=MIDDLE SRC="spc.gif">
two types of interactions between such units: (i) non-linear
<IMG WIDTH=1 HEIGHT=25 ALIGN=MIDDLE SRC="spc.gif">
self-excitation of each unit and (ii) divisive normalization of each
<IMG WIDTH=1 HEIGHT=25 ALIGN=MIDDLE SRC="spc.gif">
unit response relative to the responses of similarly tuned units.  All
<IMG WIDTH=1 HEIGHT=25 ALIGN=MIDDLE SRC="spc.gif">
model parameters are constrained by psychophysical data and an
<IMG WIDTH=1 HEIGHT=25 ALIGN=MIDDLE SRC="spc.gif">
automatic fitting procedure consistently converged to the same
<IMG WIDTH=1 HEIGHT=25 ALIGN=MIDDLE SRC="spc.gif">
parameter set regardless of the initial position in parameter space.
<P>
Our two main contributions are the small number of model components
<IMG WIDTH=1 HEIGHT=25 ALIGN=MIDDLE SRC="spc.gif">
and the unified, task-independent decision strategy.  Rather than
<IMG WIDTH=1 HEIGHT=25 ALIGN=MIDDLE SRC="spc.gif">
making different assumptions about the decision strategy in different
<IMG WIDTH=1 HEIGHT=25 ALIGN=MIDDLE SRC="spc.gif">
behavioral tasks, we combine the information contained in the
<IMG WIDTH=1 HEIGHT=25 ALIGN=MIDDLE SRC="spc.gif">
responses of all model units in a manner that is optimal for any
<IMG WIDTH=1 HEIGHT=25 ALIGN=MIDDLE SRC="spc.gif">
behavioral task.  We suggest that human observers adopt a similarly
<IMG WIDTH=1 HEIGHT=25 ALIGN=MIDDLE SRC="spc.gif">
optimal decision procedure as they become familiar with a particular
<IMG WIDTH=1 HEIGHT=25 ALIGN=MIDDLE SRC="spc.gif">
task (&quot;task set&quot;).  Although here we apply this decision strategy only
<IMG WIDTH=1 HEIGHT=25 ALIGN=MIDDLE SRC="spc.gif">
to the discrimination of stimulus contrast, orientation, and spatial
<IMG WIDTH=1 HEIGHT=25 ALIGN=MIDDLE SRC="spc.gif">
frequency, it can readily be generalized to arbitrary discriminations
<IMG WIDTH=1 HEIGHT=25 ALIGN=MIDDLE SRC="spc.gif">
such as, for example, the discrimination of vernier targets.
<P>
So far we have considered only situations in which the same decision
<IMG WIDTH=1 HEIGHT=25 ALIGN=MIDDLE SRC="spc.gif">
strategy is optimal for every stimulus presentation.  We are now
<IMG WIDTH=1 HEIGHT=25 ALIGN=MIDDLE SRC="spc.gif">
studying situations in which the optimal decision strategy varies
<IMG WIDTH=1 HEIGHT=25 ALIGN=MIDDLE SRC="spc.gif">
unpredictably from trial to trial (&quot;decision uncertainty&quot;).  For
<IMG WIDTH=1 HEIGHT=25 ALIGN=MIDDLE SRC="spc.gif">
example, situations in which the observer attempts to detect an
<IMG WIDTH=1 HEIGHT=25 ALIGN=MIDDLE SRC="spc.gif">
increase in either the spatial frequency or the contrast of stimulus.
<IMG WIDTH=1 HEIGHT=25 ALIGN=MIDDLE SRC="spc.gif">
In this way, we hope to learn the extent to which our model reflects
<IMG WIDTH=1 HEIGHT=25 ALIGN=MIDDLE SRC="spc.gif">
the decision strategy adopted by human observers in an even wider
<IMG WIDTH=1 HEIGHT=25 ALIGN=MIDDLE SRC="spc.gif">
range of situations. We have also assumed that the model's units were
<IMG WIDTH=1 HEIGHT=25 ALIGN=MIDDLE SRC="spc.gif">
independent, which is not strictly true in biological systems
<IMG WIDTH=1 HEIGHT=25 ALIGN=MIDDLE SRC="spc.gif">
(although the main source of correlation between neurons is the
<IMG WIDTH=1 HEIGHT=25 ALIGN=MIDDLE SRC="spc.gif">
overlap between their respective tuning curves, which is accounted for
<IMG WIDTH=1 HEIGHT=25 ALIGN=MIDDLE SRC="spc.gif">
in the model). The mathematical developments necessary to account for
<IMG WIDTH=1 HEIGHT=25 ALIGN=MIDDLE SRC="spc.gif">
fixed or variable covariance between units are currently under study.
<P>
In contrast to other models of early visual processing
<IMG WIDTH=1 HEIGHT=25 ALIGN=MIDDLE SRC="spc.gif">
[<A HREF="node10.html#Heeger91">5</A>, <A HREF="node10.html#Heeger92">6</A>], we find that the psychophysical data is
<IMG WIDTH=1 HEIGHT=25 ALIGN=MIDDLE SRC="spc.gif">
consistent only with interactions between similarly tuned units (e.g.,
<IMG WIDTH=1 HEIGHT=25 ALIGN=MIDDLE SRC="spc.gif">
&quot;near-orientation inhibition&quot;), not with interactions between units of
<IMG WIDTH=1 HEIGHT=25 ALIGN=MIDDLE SRC="spc.gif">
very different tuning (e.g., &quot;cross-orientation inhibition&quot;).
<IMG WIDTH=1 HEIGHT=25 ALIGN=MIDDLE SRC="spc.gif">
Although such partial pooling does not render tuning functions
<IMG WIDTH=1 HEIGHT=25 ALIGN=MIDDLE SRC="spc.gif">
completely contrast-independent, an additional degree of
<IMG WIDTH=1 HEIGHT=25 ALIGN=MIDDLE SRC="spc.gif">
contrast-independence could be provided by pooling across different
<IMG WIDTH=1 HEIGHT=25 ALIGN=MIDDLE SRC="spc.gif">
spatial locations.  This issue is currently under investigation.
<P>
In conclusion, we have developed a model based on self-excitation of
<IMG WIDTH=1 HEIGHT=25 ALIGN=MIDDLE SRC="spc.gif">
each unit, divisive normalization [<A HREF="node10.html#Heeger91">5</A>, <A HREF="node10.html#Heeger92">6</A>] between
<IMG WIDTH=1 HEIGHT=25 ALIGN=MIDDLE SRC="spc.gif">
similarly tuned units, and an ideal observer decision strategy. It was
<IMG WIDTH=1 HEIGHT=25 ALIGN=MIDDLE SRC="spc.gif">
able to reproduce a wide range of human visual thresholds. The fact
<IMG WIDTH=1 HEIGHT=25 ALIGN=MIDDLE SRC="spc.gif">
that such a simple and idealized model can account quantitatively for
<IMG WIDTH=1 HEIGHT=25 ALIGN=MIDDLE SRC="spc.gif">
a wide range of psychophysical observations greatly strengthens the
<IMG WIDTH=1 HEIGHT=25 ALIGN=MIDDLE SRC="spc.gif">
notion that spatial vision thresholds reflect processing at one
<IMG WIDTH=1 HEIGHT=25 ALIGN=MIDDLE SRC="spc.gif">
particular neuroanatomical level.
<P>
<B>Acknowledgments:</B> This work was supported by
NSF-Engineering Research Center (ERC), NIMH, ONR, and the Sloan Center
for Theoretical Neurobiology.
<P>
<HR><A NAME="tex2html106" HREF="node10.html"><IMG WIDTH=37 HEIGHT=24 ALIGN=BOTTOM ALT="next" SRC="next.gif"></A> <A NAME="tex2html104" HREF="paper.html"><IMG WIDTH=26 HEIGHT=24 ALIGN=BOTTOM ALT="up" SRC="up.gif"></A> <A NAME="tex2html98" HREF="node8.html"><IMG WIDTH=63 HEIGHT=24 ALIGN=BOTTOM ALT="previous" SRC="prev.gif"></A>   <BR>
<B> Next:</B> <A NAME="tex2html107" HREF="node10.html">References</A>
<B>Up:</B> <A NAME="tex2html105" HREF="paper.html">A Model of Early </A>
<B> Previous:</B> <A NAME="tex2html99" HREF="node8.html">Predictions</A>
<P><ADDRESS>
<I>Laurent Itti <BR>
Mon Jan  5 01:30:37 PST 1998</I>
</ADDRESS>
</BODY>
</HTML>

